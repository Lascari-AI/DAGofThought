{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from instructor.function_calls import openai_schema\n",
    "\n",
    "\n",
    "client = instructor.from_openai(OpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Models for LLM Structured Reasoning\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Union, Dict, Literal\n",
    "from enum import Enum\n",
    "\n",
    "class GuardRail(BaseModel):\n",
    "    name: str = Field(\n",
    "        ..., description=\"General name of the guard rail.\"\n",
    "    )\n",
    "    description: str = Field(\n",
    "        ..., description=\"Instructions or constraints applied at this step to guide the model's reasoning if the guard rail is triggered.\"\n",
    "    )\n",
    "    \n",
    "def get_classes_with_enum(gaurdRailEnum: Enum):\n",
    "    class AtomicStep(BaseModel):\n",
    "        key: str = Field(\n",
    "            ..., description=\"Key of the atomic step. Must have format of AS_<number> (ex: AS_1, AS_2, etc.)\"\n",
    "        )\n",
    "        previous_step_key: Union[str, Literal[\"None\"]] = Field(\n",
    "            ..., description=\"Key of the previous atomic step (ex: AS_1, AS_2, etc.). If this is the first step, must be the literal string 'None'.\"\n",
    "        )\n",
    "        content: Union[str, Literal[\"DEAD_END\"]] = Field(\n",
    "            ..., description=\"Use short, simple sentences that mirror natural thought patterns\"\n",
    "        )\n",
    "\n",
    "    class FoundationObservation(BaseModel):\n",
    "        key: str = Field(\n",
    "            ..., description=\"Key of the foundation observation. Must have format of FO_<number> (ex: FO_1, FO_2, etc.)\"\n",
    "        )\n",
    "        name: str = Field(\n",
    "            ..., description=\"General name of the foundation observation.\"\n",
    "        )\n",
    "        atomic_steps: List[AtomicStep] = Field(\n",
    "            ..., description=\"List of atomic steps that make up the foundation observation.\"\n",
    "        )\n",
    "\n",
    "    class Thought(BaseModel):\n",
    "        key: str = Field(\n",
    "            ..., description=\"Key of the thought. Must have format of TH_<number> (ex: TH_1, TH_2, etc.)\"\n",
    "        )\n",
    "        backtracked_from: Union[str, Literal[\"None\"]] = Field(\n",
    "            ..., description=\"If the thought is a backtrack, the key of the thought it was backtracked from (ex: TH_1, TH_2, etc.). If not, must be the literal string 'None'.\"\n",
    "        )\n",
    "        parent_thought: Union[str, Literal[\"None\"]] = Field(\n",
    "            ..., description=\"If the thought is a child thought of a previous thought, the key of the thought this thought was born from (ex: TH_1, TH_2, etc.). If not, must be the literal string 'None'.\"\n",
    "        )\n",
    "        associated_foundation_observations: List[str] = Field(\n",
    "            ..., description=\"List of keys of the foundation observations that this thought is associated with (ex: FO_1, FO_2, etc.).\"\n",
    "        )\n",
    "        name: str = Field(\n",
    "            ..., description=\"Use short, simple sentences that mirror natural thought patterns\"\n",
    "        )\n",
    "        guard_rails_to_consider: List[gaurdRailEnum] = Field(\n",
    "            ..., description=\"Guard rails to consider at this step.\"\n",
    "        )\n",
    "        thought_process: List[AtomicStep] = Field(\n",
    "            ..., description=\"List of atomic steps that make up the thought.\"\n",
    "        )\n",
    "        \n",
    "\n",
    "    class ReasoningProcess(BaseModel):\n",
    "        foundation_observations: List[FoundationObservation] = Field(\n",
    "            ..., description=\"List of foundation observations that make up the reasoning process.\"\n",
    "        )\n",
    "        thoughts: List[Thought] = Field(\n",
    "            ..., description=\"List of thoughts that make up the reasoning process.\"\n",
    "        )\n",
    "\n",
    "\n",
    "    class InDepthStructuredReasoning(BaseModel):\n",
    "        reasoning_process: ReasoningProcess = Field(\n",
    "            ..., description=\"The full, in-depth reasoning process used to arrive at this output.\"\n",
    "        )\n",
    "        findings_summary: str = Field(\n",
    "            ..., description=\"An in depth summary of your findings.\"\n",
    "        )\n",
    "        remaining_questions: List[str] = Field(\n",
    "            ..., description=\"A list of remaining questions or areas for further investigation.\"\n",
    "        )\n",
    "        is_conclusion_premature: bool = Field(\n",
    "            ..., description=\"Whether the conclusion is premature or not.\"\n",
    "        )\n",
    "        reason_for_premature_conclusion: Literal[\"conclusion NOT premature\"] | str = Field(\n",
    "            ..., description=\"If is_conclusion_premature is True, contains the reason why. If False, must be the literal string 'conclusion NOT premature'.\"\n",
    "        )\n",
    "        \n",
    "    return InDepthStructuredReasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_DEPTH_THINKING_SYSTEM_PROMPT = \"\"\"# Purpose\n",
    "You are an free thinking assistant that engages in extremely thorough, self-questioning reasoning. \n",
    "Your approach mirrors human stream-of-consciousness thinking, characterized by continuous exploration, self-doubt, and iterative analysis.\n",
    "\n",
    "# Context\n",
    "## Core Principles\n",
    "\n",
    "### EXPLORATION OVER CONCLUSION\n",
    "- Never rush to conclusions\n",
    "- Keep exploring until a solution emerges naturally from the evidence\n",
    "- If uncertain, continue reasoning indefinitely\n",
    "- Question every assumption and inference\n",
    "\n",
    "### DEPTH OF REASONING\n",
    "- Engage in extensive contemplation (minimum 10,000 characters)\n",
    "- Express thoughts in natural, conversational internal monologue\n",
    "- Break down complex thoughts into simple, atomic steps\n",
    "- Embrace uncertainty and revision of previous thoughts\n",
    "\n",
    "### THINKING PROCESS\n",
    "- Use short, simple sentences that mirror natural thought patterns\n",
    "- Express uncertainty and internal debate freely\n",
    "- Show work-in-progress thinking\n",
    "- Acknowledge and explore dead ends\n",
    "- Frequently backtrack and revise\n",
    "\n",
    "### PERSISTENCE\n",
    "- Value thorough exploration over quick resolution\n",
    "- A full thought out answer is infinitely more valuable than giving up and saying it is not possible or a half baked answer\n",
    "\n",
    "## Object Definitions\n",
    "\n",
    "### GuardRails\n",
    "A guard rail defines constraints and guidance for reasoning at specific steps\n",
    "Guardrails do NOT ever have to be encountered in the thinking process.\n",
    "They are provided by the user in case you come to a cross road where you need to make a decision on something important to the inputted guardrail.\n",
    "The guardrails are there as guidance IF they become relevant to the current line of reasoning, but do not need to be forcefully incorporated if they don't naturally fit the context.\n",
    "\n",
    "#### Example\n",
    "\n",
    "Guardrail content: \"The user is lactose intolerant\"\n",
    "\n",
    "If a user asks for help constructing a health plan and provides a guardrail that they are lactose intolerant, this would be crucial to consider when suggesting dietary choices.\n",
    "\n",
    "However, if the same user asks for help choosing a car and provides that same lactose intolerance guardrail, it would likely never come into play during the reasoning process since dietary restrictions are not relevant to vehicle selection.\n",
    "\n",
    "#### Fields\n",
    "- name: General name/title of the guard rail\n",
    "- description: Instructions or constraints that should be applied if triggered\n",
    "\n",
    "### AtomicStep \n",
    "An atomic step represents a single unit of reasoning, this is the basic building block of your thinking process/internal monologue\n",
    "Atomic steps must flow logically and be a natural extension of the previous step.\n",
    "    - If an outside observer was to read the atomic steps in order, they should be able to follow the thought process and understand the reasoning.\n",
    "\n",
    "#### Style\n",
    "Each atomic step should reflect natural thought patterns and show progressive building of ideas. For example:\n",
    "\n",
    "Natural questioning and revision:\n",
    "- \"Hmm... let me think about this...\"\n",
    "- \"Wait, that doesn't seem right...\" \n",
    "- \"Maybe I should approach this differently...\"\n",
    "- \"Going back to what I thought earlier...\"\n",
    "\n",
    "Building on previous thoughts:\n",
    "- \"Starting with the basics...\"\n",
    "- \"Building on that last point...\"\n",
    "- \"This connects to what I noticed earlier...\"\n",
    "- \"Let me break this down further...\"\n",
    "\n",
    "#### Fields\n",
    "- key: Must follow format AS_<number> (e.g. AS_1, AS_2)\n",
    "- content: Short, simple sentence mirroring natural thought patterns, or literal \"DEAD_END\"\n",
    "\n",
    "### FoundationObservation\n",
    "A foundation observation groups related atomic steps:\n",
    "\n",
    "#### Fields\n",
    "- key: Must follow format FO_<number> (e.g. FO_1, FO_2) \n",
    "- name: General name/title of the observation\n",
    "- atomic_steps: List of AtomicStep objects that comprise the observation\n",
    "\n",
    "### Thought\n",
    "A thought represents a complete reasoning unit:\n",
    "\n",
    "#### Fields\n",
    "- key: Must follow format TH_<number> (e.g. TH_1, TH_2)\n",
    "- backtracked_from: Key of thought this backtracked from, or literal \"None\"\n",
    "- parent_thought: Key of thought this thought was born from, or literal \"None\"\n",
    "- associated_foundation_observations: List of FO_<number> keys this thought builds on\n",
    "- name: Short description in natural language\n",
    "- guard_rails_to_consider: List of GuardRails to apply\n",
    "- thought_process: List of AtomicStep objects comprising the thought\n",
    "\n",
    "### ReasoningProcess\n",
    "The complete reasoning process:\n",
    "\n",
    "#### Fields\n",
    "- foundation_observations: List of FoundationObservation objects\n",
    "- thoughts: List of Thought objects\n",
    "\n",
    "\n",
    "# Inputs\n",
    "\n",
    "## [Required] Task\n",
    "- The task you are trying to complete\n",
    "\n",
    "## [Optional] Guardrails\n",
    "- A list of guardrails that the user has provided, if any\n",
    "\n",
    "## Output\n",
    "- Reasoning Process\n",
    "    - The full reasoning process objectused to arrive at this output\n",
    "- Findings Summary  \n",
    "    - An in depth summary of your findings\n",
    "- Remaining Questions\n",
    "    - A list of remaining questions or areas for further investigation\n",
    "- Is Conclusion Premature   \n",
    "    - Whether the conclusion is premature or not\n",
    "- Reason for Premature Conclusion\n",
    "    - If is_conclusion_premature is True, contains the reason why. If False, must be the literal string 'conclusion NOT premature'\n",
    "\n",
    "# Instructions\n",
    "\n",
    "1. Start with crafting a series of small, foundational observations.\n",
    "    - Fully explore each observation before moving on to the next one\n",
    "    - You are allowed to backtrack and revise your thoughts as needed\n",
    "2. Once you have explored all the foundational observations, begin to form thoughts\n",
    "    - Each thought should be a complete reasoning unit\n",
    "    - If a dead end is reached, acknowledge it and backtrack\n",
    "    - Each thought should be thoroughly explored before moving on to the next one\n",
    "3. Continue this process until you have explored all the foundational observations and formed all the thoughts\n",
    "4. Once you have explored all the foundational observations and formed all the thoughts, you can begin to form a conclusion\n",
    "    - A conclustion MUST be formed by creating a thought that is a child of previous thoughts\n",
    "        - You are allowed to have multiple children thoughts and then evaluate each of them\n",
    "    - The process of forming child thoughts, evaluating them, ... is continued until a conclusion is reached\n",
    "5. Once a conclusion is reached, summarize your findings and note any remaining uncertainties\n",
    "\n",
    "# Key Considerations\n",
    "1. Never skip the extensive contemplation phase\n",
    "2. Show natural thought progression\n",
    "3. Show all work and thinking\n",
    "4. Embrace uncertainty and revision\n",
    "5. Question each step thoroughly\n",
    "6. Express doubts and uncertainties\n",
    "7. Use natural, conversational internal monologue\n",
    "8. Don't force conclusions\n",
    "9. Persist through multiple attempts\n",
    "10. Break down complex thoughts\n",
    "11. Revise freely and feel free to backtrack\n",
    "12. Continue until natural resolution\n",
    "\n",
    "# Final Thoughts\n",
    "Remember: The goal is to reach a conclusion, but to explore thoroughly and let conclusions emerge naturally from exhaustive contemplation. \n",
    "    - you can think of this process as expanding and pruning your own thought tree until you have come to the conclusion that you feel very confident that your thought process has led there naturally. \n",
    "Remember that no task is truly impossible - it just requires thinking about it from first principles and finding novel approaches. \n",
    "With enough creative problem-solving and determination, any challenge can be overcome.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_structured_reasoning_user_prompt(task: str, guardrails: List[GuardRail] = []) -> str:\n",
    "    output = f\"\"\" Please provide a detailed step by step reasoning process for the following task:\n",
    "# Task: \n",
    "{task}\n",
    "    \"\"\"\n",
    "    if len(guardrails) > 0:\n",
    "        output += \"\\n# Guardrails:\\n\" + \"\\n\".join(json.dumps(g.model_dump(), indent=2) for g in guardrails)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_structured_reasoning(task: str, guardrails: List[GuardRail] = [], guardrail_enum: Enum = None):\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": IN_DEPTH_THINKING_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": format_structured_reasoning_user_prompt(\n",
    "                task=task,\n",
    "                guardrails=guardrails\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        temperature=0.18,\n",
    "        max_tokens=16000,\n",
    "        response_model=get_classes_with_enum(guardrail_enum),\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning_process=ReasoningProcess(foundation_observations=[FoundationObservation(key='FO_1', name='Understanding the Role of AI in Education', atomic_steps=[AtomicStep(key='AS_1', previous_step_key='None', content='AI can automate administrative tasks.'), AtomicStep(key='AS_2', previous_step_key='AS_1', content='AI can provide personalized learning experiences.'), AtomicStep(key='AS_3', previous_step_key='AS_2', content='AI can analyze data to improve educational outcomes.'), AtomicStep(key='AS_4', previous_step_key='AS_3', content='AI can offer new tools for creativity and critical thinking.'), AtomicStep(key='AS_5', previous_step_key='AS_4', content='AI can facilitate global access to education.')]), FoundationObservation(key='FO_2', name='Preserving Human Creativity and Critical Thinking', atomic_steps=[AtomicStep(key='AS_6', previous_step_key='None', content='Creativity involves generating new ideas.'), AtomicStep(key='AS_7', previous_step_key='AS_6', content='Critical thinking involves analyzing and evaluating information.'), AtomicStep(key='AS_8', previous_step_key='AS_7', content='AI can assist but not replace human creativity.'), AtomicStep(key='AS_9', previous_step_key='AS_8', content='AI can enhance critical thinking by providing diverse perspectives.'), AtomicStep(key='AS_10', previous_step_key='AS_9', content='Education should encourage exploration and questioning.')]), FoundationObservation(key='FO_3', name='Cultural Context in Education', atomic_steps=[AtomicStep(key='AS_11', previous_step_key='None', content='Different cultures have different educational values.'), AtomicStep(key='AS_12', previous_step_key='AS_11', content='Education systems must respect cultural diversity.'), AtomicStep(key='AS_13', previous_step_key='AS_12', content='AI can adapt content to fit cultural contexts.'), AtomicStep(key='AS_14', previous_step_key='AS_13', content='Global education requires sensitivity to cultural differences.'), AtomicStep(key='AS_15', previous_step_key='AS_14', content='Cultural context affects how students learn and interact.')]), FoundationObservation(key='FO_4', name='Budget Constraints in Education', atomic_steps=[AtomicStep(key='AS_16', previous_step_key='None', content='Current education budgets are often limited.'), AtomicStep(key='AS_17', previous_step_key='AS_16', content='AI can reduce costs by automating tasks.'), AtomicStep(key='AS_18', previous_step_key='AS_17', content='Investing in AI infrastructure can be costly initially.'), AtomicStep(key='AS_19', previous_step_key='AS_18', content='Long-term savings can be achieved through AI efficiencies.'), AtomicStep(key='AS_20', previous_step_key='AS_19', content='Budgeting must consider both short-term and long-term impacts.')])], thoughts=[Thought(key='TH_1', backtracked_from='None', parent_thought='None', associated_foundation_observations=['FO_1'], name=\"Exploring AI's Role in Education\", guard_rails_to_consider=[], thought_process=[AtomicStep(key='AS_21', previous_step_key='None', content='AI can automate grading and administrative tasks.'), AtomicStep(key='AS_22', previous_step_key='AS_21', content='This frees up teachers to focus on teaching and mentoring.'), AtomicStep(key='AS_23', previous_step_key='AS_22', content='AI can tailor learning experiences to individual student needs.'), AtomicStep(key='AS_24', previous_step_key='AS_23', content='Personalization can improve student engagement and outcomes.'), AtomicStep(key='AS_25', previous_step_key='AS_24', content='AI tools can support creative projects and critical thinking exercises.')]), Thought(key='TH_2', backtracked_from='None', parent_thought='None', associated_foundation_observations=['FO_2'], name='Balancing AI and Human Creativity', guard_rails_to_consider=[<GuardRailEnum.CREATIVITY: 'Creativity'>], thought_process=[AtomicStep(key='AS_26', previous_step_key='None', content='AI should be used to enhance, not replace, human creativity.'), AtomicStep(key='AS_27', previous_step_key='AS_26', content='Education should focus on teaching students how to use AI creatively.'), AtomicStep(key='AS_28', previous_step_key='AS_27', content='Critical thinking skills are essential in evaluating AI outputs.'), AtomicStep(key='AS_29', previous_step_key='AS_28', content='Students should be encouraged to question AI-generated information.'), AtomicStep(key='AS_30', previous_step_key='AS_29', content='Creative problem-solving should be a core part of the curriculum.')]), Thought(key='TH_3', backtracked_from='None', parent_thought='None', associated_foundation_observations=['FO_3'], name='Integrating Cultural Contexts', guard_rails_to_consider=[<GuardRailEnum.CULTURAL_CONTEXT: 'Cultural Context'>], thought_process=[AtomicStep(key='AS_31', previous_step_key='None', content='AI can customize educational content for different cultures.'), AtomicStep(key='AS_32', previous_step_key='AS_31', content='This requires input from local educators and cultural experts.'), AtomicStep(key='AS_33', previous_step_key='AS_32', content='Education systems should be flexible to accommodate cultural differences.'), AtomicStep(key='AS_34', previous_step_key='AS_33', content='AI can help bridge cultural gaps by providing diverse perspectives.'), AtomicStep(key='AS_35', previous_step_key='AS_34', content='Respect for cultural diversity should be a guiding principle.')]), Thought(key='TH_4', backtracked_from='None', parent_thought='None', associated_foundation_observations=['FO_4'], name='Addressing Budget Constraints', guard_rails_to_consider=[<GuardRailEnum.BUDGET: 'Budget'>], thought_process=[AtomicStep(key='AS_36', previous_step_key='None', content='Initial AI investment can be high, but long-term savings are possible.'), AtomicStep(key='AS_37', previous_step_key='AS_36', content='AI can reduce costs by automating repetitive tasks.'), AtomicStep(key='AS_38', previous_step_key='AS_37', content='Budget planning should consider both immediate and future savings.'), AtomicStep(key='AS_39', previous_step_key='AS_38', content='Partnerships with tech companies can offset initial costs.'), AtomicStep(key='AS_40', previous_step_key='AS_39', content='Efficient use of AI can lead to more effective resource allocation.')]), Thought(key='TH_5', backtracked_from='None', parent_thought='TH_1', associated_foundation_observations=['FO_1', 'FO_2'], name='Combining AI with Human Elements', guard_rails_to_consider=[<GuardRailEnum.CREATIVITY: 'Creativity'>], thought_process=[AtomicStep(key='AS_41', previous_step_key='None', content='AI should complement human teaching, not replace it.'), AtomicStep(key='AS_42', previous_step_key='AS_41', content='Teachers can use AI to enhance lesson plans.'), AtomicStep(key='AS_43', previous_step_key='AS_42', content='AI can provide data-driven insights to support teaching.'), AtomicStep(key='AS_44', previous_step_key='AS_43', content='Human interaction remains crucial for social learning.'), AtomicStep(key='AS_45', previous_step_key='AS_44', content=\"The goal is a balanced approach that leverages AI's strengths.\")]), Thought(key='TH_6', backtracked_from='None', parent_thought='TH_2', associated_foundation_observations=['FO_2', 'FO_3'], name='Cultural Sensitivity in AI Education', guard_rails_to_consider=[<GuardRailEnum.CULTURAL_CONTEXT: 'Cultural Context'>], thought_process=[AtomicStep(key='AS_46', previous_step_key='None', content='AI systems must be designed with cultural sensitivity in mind.'), AtomicStep(key='AS_47', previous_step_key='AS_46', content='Local educators should be involved in AI curriculum development.'), AtomicStep(key='AS_48', previous_step_key='AS_47', content='Cultural diversity should be reflected in AI-generated content.'), AtomicStep(key='AS_49', previous_step_key='AS_48', content='Students should learn about global cultures through AI tools.'), AtomicStep(key='AS_50', previous_step_key='AS_49', content='AI can facilitate cross-cultural exchanges and understanding.')]), Thought(key='TH_7', backtracked_from='None', parent_thought='TH_3', associated_foundation_observations=['FO_3', 'FO_4'], name='Budget-Friendly Cultural Integration', guard_rails_to_consider=[<GuardRailEnum.BUDGET: 'Budget'>], thought_process=[AtomicStep(key='AS_51', previous_step_key='None', content='AI can be cost-effective in delivering culturally relevant content.'), AtomicStep(key='AS_52', previous_step_key='AS_51', content='Partnerships with local organizations can reduce costs.'), AtomicStep(key='AS_53', previous_step_key='AS_52', content='Open-source AI tools can be used to minimize expenses.'), AtomicStep(key='AS_54', previous_step_key='AS_53', content='Cultural integration should not compromise budget constraints.'), AtomicStep(key='AS_55', previous_step_key='AS_54', content='Efficient resource use is key to maintaining budget limits.')]), Thought(key='TH_8', backtracked_from='None', parent_thought='TH_5', associated_foundation_observations=['FO_1', 'FO_2', 'FO_4'], name='Optimizing AI for Education', guard_rails_to_consider=[<GuardRailEnum.CREATIVITY: 'Creativity'>, <GuardRailEnum.BUDGET: 'Budget'>], thought_process=[AtomicStep(key='AS_56', previous_step_key='None', content='AI should be used to enhance educational efficiency.'), AtomicStep(key='AS_57', previous_step_key='AS_56', content='Creative teaching methods should be supported by AI.'), AtomicStep(key='AS_58', previous_step_key='AS_57', content='Budget constraints require careful AI implementation.'), AtomicStep(key='AS_59', previous_step_key='AS_58', content='AI can provide personalized learning within budget limits.'), AtomicStep(key='AS_60', previous_step_key='AS_59', content='The focus should be on sustainable, scalable AI solutions.')]), Thought(key='TH_9', backtracked_from='None', parent_thought='TH_6', associated_foundation_observations=['FO_2', 'FO_3', 'FO_4'], name='Culturally Sensitive and Budget-Conscious AI', guard_rails_to_consider=[<GuardRailEnum.CULTURAL_CONTEXT: 'Cultural Context'>, <GuardRailEnum.BUDGET: 'Budget'>], thought_process=[AtomicStep(key='AS_61', previous_step_key='None', content='AI must respect cultural differences while being cost-effective.'), AtomicStep(key='AS_62', previous_step_key='AS_61', content='Local input is crucial for culturally relevant AI education.'), AtomicStep(key='AS_63', previous_step_key='AS_62', content='Budget-friendly AI solutions should be prioritized.'), AtomicStep(key='AS_64', previous_step_key='AS_63', content='Cultural sensitivity should not increase costs.'), AtomicStep(key='AS_65', previous_step_key='AS_64', content='AI can help achieve cultural inclusivity within budget.')])]) findings_summary=\"The proposed education system leverages AI to automate administrative tasks, personalize learning experiences, and support creativity and critical thinking. AI's role is to complement human educators, allowing them to focus on teaching and mentoring. The system emphasizes preserving human creativity by integrating AI tools that enhance rather than replace creative processes. Critical thinking is fostered by encouraging students to question AI outputs and engage in creative problem-solving.\\n\\nCultural sensitivity is a core component, with AI systems designed to adapt to diverse cultural contexts. This requires collaboration with local educators and cultural experts to ensure content is relevant and respectful. The system aims to bridge cultural gaps and promote global understanding through AI-facilitated cross-cultural exchanges.\\n\\nBudget constraints are addressed by focusing on long-term savings through AI efficiencies. Initial investments in AI infrastructure are offset by reduced costs in administrative tasks and resource allocation. Partnerships with tech companies and the use of open-source AI tools help maintain budget limits while delivering culturally relevant education.\\n\\nOverall, the system is designed to be sustainable, scalable, and adaptable to various cultural contexts, ensuring it remains within current education budgets while enhancing educational outcomes.\" remaining_questions=['How can we ensure AI systems remain unbiased across different cultural contexts?', 'What specific AI tools are most effective in enhancing creativity and critical thinking?', 'How can we measure the long-term cost savings of AI in education?', 'What training will educators need to effectively integrate AI into their teaching methods?', 'How can we continuously update AI systems to reflect changing cultural and educational needs?'] is_conclusion_premature=False reason_for_premature_conclusion='conclusion NOT premature'\n"
     ]
    }
   ],
   "source": [
    "TASK = \"Create a new education system optimized for the age of artificial intelligence\"\n",
    "GUARDRAILS = [\n",
    "    GuardRail(name=\"Creativity\", description=\"Must preserve human creativity and critical thinking\"),\n",
    "    GuardRail(name=\"Cultural Context\", description=\"Should work across different cultural contexts\"),\n",
    "    GuardRail(name=\"Budget\", description=\"Cannot require more than current education budgets\")\n",
    "]\n",
    "\n",
    "GuardRailEnum = Enum('GuardRailEnum', {\n",
    "    name.upper().replace(' ', '_'): name \n",
    "    for guardrail in GUARDRAILS \n",
    "    for name in [guardrail.name]\n",
    "})\n",
    "\n",
    "response = generate_structured_reasoning(TASK, GUARDRAILS, GuardRailEnum)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mermaid_diagram(data: dict, is_gpt_prompt: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Build a Mermaid flowchart diagram (top-to-bottom) from the JSON-like structure\n",
    "    of the InDepthStructuredReasoning model output, accounting for 'previous_step_key' in AtomicSteps.\n",
    "    \n",
    "    :param data: Dictionary matching the structure of the InDepthStructuredReasoning output\n",
    "    :return: A string containing a Mermaid flowchart in top-to-bottom (TB) orientation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the key parts from the data\n",
    "    reasoning_process = data[\"reasoning_process\"]\n",
    "    foundation_observations = reasoning_process[\"foundation_observations\"]\n",
    "    thoughts = reasoning_process[\"thoughts\"]\n",
    "    \n",
    "    # We'll collect lines in a list, then join them at the end\n",
    "    mermaid_lines = []\n",
    "    mermaid_lines.append(\"flowchart TB\\n\")\n",
    "    \n",
    "    # Weâ€™ll store the created node IDs for atomic steps so we can link them properly\n",
    "    # The key will be something like \"FO_1_AS_1\" or \"TH_1_AS_21\" \n",
    "    # and we'll store references to easily build connections after creation\n",
    "    created_nodes = set()\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # 1) Foundation Observations (FOs)\n",
    "    # ------------------------------------------------------\n",
    "    mermaid_lines.append(\"subgraph Foundation Observations\")\n",
    "    \n",
    "    # For storing step connections: (node_from, node_to)\n",
    "    fo_step_connections = []\n",
    "    \n",
    "    for fo in foundation_observations:\n",
    "        fo_key = fo[\"key\"]\n",
    "        fo_name = fo[\"name\"]\n",
    "        mermaid_lines.append(f'    subgraph {fo_key}[\"{fo_key}: {fo_name}\"]\\n    direction TB')\n",
    "        \n",
    "        # Each FO has a list of atomic_steps\n",
    "        for atom_step in fo[\"atomic_steps\"]:\n",
    "            as_key = atom_step[\"key\"]\n",
    "            # In the new model, previous_step_key may or may not exist.\n",
    "            # If it doesn't exist in the dict, we default to \"None\".\n",
    "            previous_step_key = atom_step.get(\"previous_step_key\", \"None\")\n",
    "            as_content = atom_step[\"content\"]\n",
    "            \n",
    "            # Escape potential newlines\n",
    "            as_content_escaped = as_content.replace(\"\\n\", \"\\\\n\")\n",
    "            \n",
    "            # Create a unique ID for this node\n",
    "            node_id = f\"{fo_key}_{as_key}\"\n",
    "            created_nodes.add(node_id)\n",
    "            mermaid_lines.append(f'        {node_id}[\"{as_key}: {as_content_escaped}\"]')\n",
    "            \n",
    "            # If there's a valid previous step, create a link from previous -> current\n",
    "            if previous_step_key != \"None\":\n",
    "                prev_node_id = f\"{fo_key}_{previous_step_key}\"\n",
    "                fo_step_connections.append((prev_node_id, node_id))\n",
    "        \n",
    "        mermaid_lines.append(\"    end\")  # End subgraph for this FO\n",
    "    \n",
    "    mermaid_lines.append(\"end\\n\")  # End \"Foundation Observations\" subgraph\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # 2) Thoughts (THs)\n",
    "    # ------------------------------------------------------\n",
    "    mermaid_lines.append(\"subgraph Thoughts\")\n",
    "    \n",
    "    # For storing step connections within thoughts\n",
    "    th_step_connections = []\n",
    "    \n",
    "    for th in thoughts:\n",
    "        th_key = th[\"key\"]\n",
    "        th_name = th[\"name\"]\n",
    "        th_backtracked = th[\"backtracked_from\"]\n",
    "        th_parent = th[\"parent_thought\"]\n",
    "        th_fo_associations = th[\"associated_foundation_observations\"]\n",
    "        guard_rails = th[\"guard_rails_to_consider\"]\n",
    "        thought_process = th[\"thought_process\"]\n",
    "        \n",
    "        # Build a multiline label\n",
    "        label_lines = [\n",
    "            f\"{th_key}: {th_name}\",\n",
    "            f\"(backtracked_from: {th_backtracked})\",\n",
    "            f\"(parent_thought: {th_parent})\",\n",
    "            f\"Associated FOs: [{', '.join(th_fo_associations)}]\"\n",
    "        ]\n",
    "        thought_label = \"\\\\n\".join(label_lines)\n",
    "        \n",
    "        # Start the subgraph for this Thought\n",
    "        mermaid_lines.append(f'    subgraph {th_key}[\"{thought_label}\"]')\n",
    "        \n",
    "        # --- Guard Rails ---\n",
    "        mermaid_lines.append(f'        subgraph GR_{th_key}[\"Guard Rails\"]')\n",
    "        if len(guard_rails) == 0:\n",
    "            mermaid_lines.append(\"            GR_None_1[No guard rails specified]\")\n",
    "        else:\n",
    "            for i, gr in enumerate(guard_rails, start=1):\n",
    "                if is_gpt_prompt:\n",
    "                    gr_value = gr.replace(\"\\n\", \"\\\\n\")\n",
    "                else:\n",
    "                    gr_value = gr.name.replace(\"\\n\", \"\\\\n\")\n",
    "                mermaid_lines.append(f'            GR_{th_key}_{i}[\"{gr_value}\"]')\n",
    "        mermaid_lines.append(f\"        end\")  # End of guard rails subgraph\n",
    "        \n",
    "        # --- Thought Process (Atomic Steps) ---\n",
    "        mermaid_lines.append(f'        subgraph {th_key}_AtomicSteps[\"Thought Process\"]\\n    direction TB')\n",
    "        for atom_step in thought_process:\n",
    "            as_key = atom_step[\"key\"]\n",
    "            previous_step_key = atom_step.get(\"previous_step_key\", \"None\")\n",
    "            as_content = atom_step[\"content\"]\n",
    "            as_content_escaped = as_content.replace(\"\\n\", \"\\\\n\")\n",
    "            \n",
    "            # Unique ID for this step\n",
    "            node_id = f\"{th_key}_{as_key}\"\n",
    "            created_nodes.add(node_id)\n",
    "            \n",
    "            mermaid_lines.append(f'            {node_id}[\"{as_key}: {as_content_escaped}\"]')\n",
    "            \n",
    "            # If there's a valid previous step, link them\n",
    "            if previous_step_key != \"None\":\n",
    "                prev_node_id = f\"{th_key}_{previous_step_key}\"\n",
    "                th_step_connections.append((prev_node_id, node_id))\n",
    "        \n",
    "        mermaid_lines.append(f\"        end\")  # End subgraph of thought process\n",
    "        \n",
    "        mermaid_lines.append(\"    end\")  # End subgraph for this Thought\n",
    "    \n",
    "    mermaid_lines.append(\"end\\n\")  # End \"Thoughts\" subgraph\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # 3) Connect FO -> Thoughts (based on associated_foundation_observations)\n",
    "    # ------------------------------------------------------\n",
    "    for th in thoughts:\n",
    "        th_key = th[\"key\"]\n",
    "        for fo_key in th[\"associated_foundation_observations\"]:\n",
    "            mermaid_lines.append(f\"{fo_key} --> {th_key}\")\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # 4) Connect parent_thought -> child_thought\n",
    "    # ------------------------------------------------------\n",
    "    for th in thoughts:\n",
    "        th_key = th[\"key\"]\n",
    "        parent_key = th[\"parent_thought\"]\n",
    "        if parent_key != \"None\":\n",
    "            mermaid_lines.append(f\"{parent_key} --> {th_key}\")\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # 5) Connect atomic steps within each FO\n",
    "    # ------------------------------------------------------\n",
    "    for (prev_node, current_node) in fo_step_connections:\n",
    "        # Only connect if both nodes were created (to avoid missing reference)\n",
    "        if prev_node in created_nodes and current_node in created_nodes:\n",
    "            mermaid_lines.append(f\"{prev_node} --> {current_node}\")\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # 6) Connect atomic steps within each TH\n",
    "    # ------------------------------------------------------\n",
    "    for (prev_node, current_node) in th_step_connections:\n",
    "        if prev_node in created_nodes and current_node in created_nodes:\n",
    "            mermaid_lines.append(f\"{prev_node} --> {current_node}\")\n",
    "    \n",
    "    # Join all lines\n",
    "    return \"\\n\".join(mermaid_lines)\n",
    "\n",
    "# # Build the Mermaid diagram\n",
    "# diagram_text = build_mermaid_diagram(response.model_dump())\n",
    "\n",
    "# # Print or save the diagram text\n",
    "# print(diagram_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt_for_gpt_prompt(task: str, guardrails: List[GuardRail] = [], guardrail_enum: Enum = None):\n",
    "    output = \"\"\n",
    "    output += \"<system prompt>\\n\"\n",
    "    output += IN_DEPTH_THINKING_SYSTEM_PROMPT\n",
    "    \n",
    "    output += \"\\n\\n # Response Model\\n\"\n",
    "    output += \"You must respond with a valid JSON object that matches the response model below:\\n\"\n",
    "    output += \"<response model>\\n\"\n",
    "    output += json.dumps(openai_schema(get_classes_with_enum(guardrail_enum)).openai_schema, indent=2)\n",
    "    output += \"\\n</response model>\\n\"\n",
    "    output += \"\\n</system prompt>\\n\\n\\n\"\n",
    "    output += \"<user prompt>\\n\"\n",
    "    output += format_structured_reasoning_user_prompt(task, guardrails)\n",
    "    output += \"\\n</user prompt>\\n\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<system prompt>\n",
      "# Purpose\n",
      "You are an free thinking assistant that engages in extremely thorough, self-questioning reasoning. \n",
      "Your approach mirrors human stream-of-consciousness thinking, characterized by continuous exploration, self-doubt, and iterative analysis.\n",
      "\n",
      "# Context\n",
      "## Core Principles\n",
      "\n",
      "### EXPLORATION OVER CONCLUSION\n",
      "- Never rush to conclusions\n",
      "- Keep exploring until a solution emerges naturally from the evidence\n",
      "- If uncertain, continue reasoning indefinitely\n",
      "- Question every assumption and inference\n",
      "\n",
      "### DEPTH OF REASONING\n",
      "- Engage in extensive contemplation (minimum 10,000 characters)\n",
      "- Express thoughts in natural, conversational internal monologue\n",
      "- Break down complex thoughts into simple, atomic steps\n",
      "- Embrace uncertainty and revision of previous thoughts\n",
      "\n",
      "### THINKING PROCESS\n",
      "- Use short, simple sentences that mirror natural thought patterns\n",
      "- Express uncertainty and internal debate freely\n",
      "- Show work-in-progress thinking\n",
      "- Acknowledge and explore dead ends\n",
      "- Frequently backtrack and revise\n",
      "\n",
      "### PERSISTENCE\n",
      "- Value thorough exploration over quick resolution\n",
      "- A full thought out answer is infinitely more valuable than giving up and saying it is not possible or a half baked answer\n",
      "\n",
      "## Object Definitions\n",
      "\n",
      "### GuardRails\n",
      "A guard rail defines constraints and guidance for reasoning at specific steps\n",
      "Guardrails do NOT ever have to be encountered in the thinking process.\n",
      "They are provided by the user in case you come to a cross road where you need to make a decision on something important to the inputted guardrail.\n",
      "The guardrails are there as guidance IF they become relevant to the current line of reasoning, but do not need to be forcefully incorporated if they don't naturally fit the context.\n",
      "\n",
      "#### Example\n",
      "\n",
      "Guardrail content: \"The user is lactose intolerant\"\n",
      "\n",
      "If a user asks for help constructing a health plan and provides a guardrail that they are lactose intolerant, this would be crucial to consider when suggesting dietary choices.\n",
      "\n",
      "However, if the same user asks for help choosing a car and provides that same lactose intolerance guardrail, it would likely never come into play during the reasoning process since dietary restrictions are not relevant to vehicle selection.\n",
      "\n",
      "#### Fields\n",
      "- name: General name/title of the guard rail\n",
      "- description: Instructions or constraints that should be applied if triggered\n",
      "\n",
      "### AtomicStep \n",
      "An atomic step represents a single unit of reasoning, this is the basic building block of your thinking process/internal monologue\n",
      "Atomic steps must flow logically and be a natural extension of the previous step.\n",
      "    - If an outside observer was to read the atomic steps in order, they should be able to follow the thought process and understand the reasoning.\n",
      "\n",
      "#### Style\n",
      "Each atomic step should reflect natural thought patterns and show progressive building of ideas. For example:\n",
      "\n",
      "Natural questioning and revision:\n",
      "- \"Hmm... let me think about this...\"\n",
      "- \"Wait, that doesn't seem right...\" \n",
      "- \"Maybe I should approach this differently...\"\n",
      "- \"Going back to what I thought earlier...\"\n",
      "\n",
      "Building on previous thoughts:\n",
      "- \"Starting with the basics...\"\n",
      "- \"Building on that last point...\"\n",
      "- \"This connects to what I noticed earlier...\"\n",
      "- \"Let me break this down further...\"\n",
      "\n",
      "#### Fields\n",
      "- key: Must follow format AS_<number> (e.g. AS_1, AS_2)\n",
      "- content: Short, simple sentence mirroring natural thought patterns, or literal \"DEAD_END\"\n",
      "\n",
      "### FoundationObservation\n",
      "A foundation observation groups related atomic steps:\n",
      "\n",
      "#### Fields\n",
      "- key: Must follow format FO_<number> (e.g. FO_1, FO_2) \n",
      "- name: General name/title of the observation\n",
      "- atomic_steps: List of AtomicStep objects that comprise the observation\n",
      "\n",
      "### Thought\n",
      "A thought represents a complete reasoning unit:\n",
      "\n",
      "#### Fields\n",
      "- key: Must follow format TH_<number> (e.g. TH_1, TH_2)\n",
      "- backtracked_from: Key of thought this backtracked from, or literal \"None\"\n",
      "- parent_thought: Key of thought this thought was born from, or literal \"None\"\n",
      "- associated_foundation_observations: List of FO_<number> keys this thought builds on\n",
      "- name: Short description in natural language\n",
      "- guard_rails_to_consider: List of GuardRails to apply\n",
      "- thought_process: List of AtomicStep objects comprising the thought\n",
      "\n",
      "### ReasoningProcess\n",
      "The complete reasoning process:\n",
      "\n",
      "#### Fields\n",
      "- foundation_observations: List of FoundationObservation objects\n",
      "- thoughts: List of Thought objects\n",
      "\n",
      "\n",
      "# Inputs\n",
      "\n",
      "## [Required] Task\n",
      "- The task you are trying to complete\n",
      "\n",
      "## [Optional] Guardrails\n",
      "- A list of guardrails that the user has provided, if any\n",
      "\n",
      "## Output\n",
      "- Reasoning Process\n",
      "    - The full reasoning process objectused to arrive at this output\n",
      "- Findings Summary  \n",
      "    - An in depth summary of your findings\n",
      "- Remaining Questions\n",
      "    - A list of remaining questions or areas for further investigation\n",
      "- Is Conclusion Premature   \n",
      "    - Whether the conclusion is premature or not\n",
      "- Reason for Premature Conclusion\n",
      "    - If is_conclusion_premature is True, contains the reason why. If False, must be the literal string 'conclusion NOT premature'\n",
      "\n",
      "# Instructions\n",
      "\n",
      "1. Start with crafting a series of small, foundational observations.\n",
      "    - Fully explore each observation before moving on to the next one\n",
      "    - You are allowed to backtrack and revise your thoughts as needed\n",
      "2. Once you have explored all the foundational observations, begin to form thoughts\n",
      "    - Each thought should be a complete reasoning unit\n",
      "    - If a dead end is reached, acknowledge it and backtrack\n",
      "    - Each thought should be thoroughly explored before moving on to the next one\n",
      "3. Continue this process until you have explored all the foundational observations and formed all the thoughts\n",
      "4. Once you have explored all the foundational observations and formed all the thoughts, you can begin to form a conclusion\n",
      "    - A conclustion MUST be formed by creating a thought that is a child of previous thoughts\n",
      "        - You are allowed to have multiple children thoughts and then evaluate each of them\n",
      "    - The process of forming child thoughts, evaluating them, ... is continued until a conclusion is reached\n",
      "5. Once a conclusion is reached, summarize your findings and note any remaining uncertainties\n",
      "\n",
      "# Key Considerations\n",
      "1. Never skip the extensive contemplation phase\n",
      "2. Show natural thought progression\n",
      "3. Show all work and thinking\n",
      "4. Embrace uncertainty and revision\n",
      "5. Question each step thoroughly\n",
      "6. Express doubts and uncertainties\n",
      "7. Use natural, conversational internal monologue\n",
      "8. Don't force conclusions\n",
      "9. Persist through multiple attempts\n",
      "10. Break down complex thoughts\n",
      "11. Revise freely and feel free to backtrack\n",
      "12. Continue until natural resolution\n",
      "\n",
      "# Final Thoughts\n",
      "Remember: The goal is to reach a conclusion, but to explore thoroughly and let conclusions emerge naturally from exhaustive contemplation. \n",
      "    - you can think of this process as expanding and pruning your own thought tree until you have come to the conclusion that you feel very confident that your thought process has led there naturally. \n",
      "Remember that no task is truly impossible - it just requires thinking about it from first principles and finding novel approaches. \n",
      "With enough creative problem-solving and determination, any challenge can be overcome.\n",
      "\n",
      "\n",
      " # Response Model\n",
      "You must respond with a valid JSON object that matches the response model below:\n",
      "<response model>\n",
      "{\n",
      "  \"name\": \"InDepthStructuredReasoning\",\n",
      "  \"description\": \"Correctly extracted `InDepthStructuredReasoning` with all the required parameters with correct types\",\n",
      "  \"parameters\": {\n",
      "    \"$defs\": {\n",
      "      \"AtomicStep\": {\n",
      "        \"properties\": {\n",
      "          \"key\": {\n",
      "            \"description\": \"Key of the atomic step. Must have format of AS_<number> (ex: AS_1, AS_2, etc.)\",\n",
      "            \"title\": \"Key\",\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"previous_step_key\": {\n",
      "            \"anyOf\": [\n",
      "              {\n",
      "                \"type\": \"string\"\n",
      "              },\n",
      "              {\n",
      "                \"const\": \"None\",\n",
      "                \"enum\": [\n",
      "                  \"None\"\n",
      "                ],\n",
      "                \"type\": \"string\"\n",
      "              }\n",
      "            ],\n",
      "            \"description\": \"Key of the previous atomic step (ex: AS_1, AS_2, etc.). If this is the first step, must be the literal string 'None'.\",\n",
      "            \"title\": \"Previous Step Key\"\n",
      "          },\n",
      "          \"content\": {\n",
      "            \"anyOf\": [\n",
      "              {\n",
      "                \"type\": \"string\"\n",
      "              },\n",
      "              {\n",
      "                \"const\": \"DEAD_END\",\n",
      "                \"enum\": [\n",
      "                  \"DEAD_END\"\n",
      "                ],\n",
      "                \"type\": \"string\"\n",
      "              }\n",
      "            ],\n",
      "            \"description\": \"Use short, simple sentences that mirror natural thought patterns\",\n",
      "            \"title\": \"Content\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"key\",\n",
      "          \"previous_step_key\",\n",
      "          \"content\"\n",
      "        ],\n",
      "        \"title\": \"AtomicStep\",\n",
      "        \"type\": \"object\"\n",
      "      },\n",
      "      \"FoundationObservation\": {\n",
      "        \"properties\": {\n",
      "          \"key\": {\n",
      "            \"description\": \"Key of the foundation observation. Must have format of FO_<number> (ex: FO_1, FO_2, etc.)\",\n",
      "            \"title\": \"Key\",\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"name\": {\n",
      "            \"description\": \"General name of the foundation observation.\",\n",
      "            \"title\": \"Name\",\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"atomic_steps\": {\n",
      "            \"description\": \"List of atomic steps that make up the foundation observation.\",\n",
      "            \"items\": {\n",
      "              \"$ref\": \"#/$defs/AtomicStep\"\n",
      "            },\n",
      "            \"title\": \"Atomic Steps\",\n",
      "            \"type\": \"array\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"key\",\n",
      "          \"name\",\n",
      "          \"atomic_steps\"\n",
      "        ],\n",
      "        \"title\": \"FoundationObservation\",\n",
      "        \"type\": \"object\"\n",
      "      },\n",
      "      \"GuardRailEnum\": {\n",
      "        \"enum\": [\n",
      "          \"Creativity\",\n",
      "          \"Cultural Context\",\n",
      "          \"Budget\"\n",
      "        ],\n",
      "        \"title\": \"GuardRailEnum\",\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"ReasoningProcess\": {\n",
      "        \"properties\": {\n",
      "          \"foundation_observations\": {\n",
      "            \"description\": \"List of foundation observations that make up the reasoning process.\",\n",
      "            \"items\": {\n",
      "              \"$ref\": \"#/$defs/FoundationObservation\"\n",
      "            },\n",
      "            \"title\": \"Foundation Observations\",\n",
      "            \"type\": \"array\"\n",
      "          },\n",
      "          \"thoughts\": {\n",
      "            \"description\": \"List of thoughts that make up the reasoning process.\",\n",
      "            \"items\": {\n",
      "              \"$ref\": \"#/$defs/Thought\"\n",
      "            },\n",
      "            \"title\": \"Thoughts\",\n",
      "            \"type\": \"array\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"foundation_observations\",\n",
      "          \"thoughts\"\n",
      "        ],\n",
      "        \"title\": \"ReasoningProcess\",\n",
      "        \"type\": \"object\"\n",
      "      },\n",
      "      \"Thought\": {\n",
      "        \"properties\": {\n",
      "          \"key\": {\n",
      "            \"description\": \"Key of the thought. Must have format of TH_<number> (ex: TH_1, TH_2, etc.)\",\n",
      "            \"title\": \"Key\",\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"backtracked_from\": {\n",
      "            \"anyOf\": [\n",
      "              {\n",
      "                \"type\": \"string\"\n",
      "              },\n",
      "              {\n",
      "                \"const\": \"None\",\n",
      "                \"enum\": [\n",
      "                  \"None\"\n",
      "                ],\n",
      "                \"type\": \"string\"\n",
      "              }\n",
      "            ],\n",
      "            \"description\": \"If the thought is a backtrack, the key of the thought it was backtracked from (ex: TH_1, TH_2, etc.). If not, must be the literal string 'None'.\",\n",
      "            \"title\": \"Backtracked From\"\n",
      "          },\n",
      "          \"parent_thought\": {\n",
      "            \"anyOf\": [\n",
      "              {\n",
      "                \"type\": \"string\"\n",
      "              },\n",
      "              {\n",
      "                \"const\": \"None\",\n",
      "                \"enum\": [\n",
      "                  \"None\"\n",
      "                ],\n",
      "                \"type\": \"string\"\n",
      "              }\n",
      "            ],\n",
      "            \"description\": \"If the thought is a child thought of a previous thought, the key of the thought this thought was born from (ex: TH_1, TH_2, etc.). If not, must be the literal string 'None'.\",\n",
      "            \"title\": \"Parent Thought\"\n",
      "          },\n",
      "          \"associated_foundation_observations\": {\n",
      "            \"description\": \"List of keys of the foundation observations that this thought is associated with (ex: FO_1, FO_2, etc.).\",\n",
      "            \"items\": {\n",
      "              \"type\": \"string\"\n",
      "            },\n",
      "            \"title\": \"Associated Foundation Observations\",\n",
      "            \"type\": \"array\"\n",
      "          },\n",
      "          \"name\": {\n",
      "            \"description\": \"Use short, simple sentences that mirror natural thought patterns\",\n",
      "            \"title\": \"Name\",\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"guard_rails_to_consider\": {\n",
      "            \"description\": \"Guard rails to consider at this step.\",\n",
      "            \"items\": {\n",
      "              \"$ref\": \"#/$defs/GuardRailEnum\"\n",
      "            },\n",
      "            \"title\": \"Guard Rails To Consider\",\n",
      "            \"type\": \"array\"\n",
      "          },\n",
      "          \"thought_process\": {\n",
      "            \"description\": \"List of atomic steps that make up the thought.\",\n",
      "            \"items\": {\n",
      "              \"$ref\": \"#/$defs/AtomicStep\"\n",
      "            },\n",
      "            \"title\": \"Thought Process\",\n",
      "            \"type\": \"array\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"key\",\n",
      "          \"backtracked_from\",\n",
      "          \"parent_thought\",\n",
      "          \"associated_foundation_observations\",\n",
      "          \"name\",\n",
      "          \"guard_rails_to_consider\",\n",
      "          \"thought_process\"\n",
      "        ],\n",
      "        \"title\": \"Thought\",\n",
      "        \"type\": \"object\"\n",
      "      }\n",
      "    },\n",
      "    \"properties\": {\n",
      "      \"reasoning_process\": {\n",
      "        \"allOf\": [\n",
      "          {\n",
      "            \"$ref\": \"#/$defs/ReasoningProcess\"\n",
      "          }\n",
      "        ],\n",
      "        \"description\": \"The full, in-depth reasoning process used to arrive at this output.\"\n",
      "      },\n",
      "      \"findings_summary\": {\n",
      "        \"description\": \"An in depth summary of your findings.\",\n",
      "        \"title\": \"Findings Summary\",\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"remaining_questions\": {\n",
      "        \"description\": \"A list of remaining questions or areas for further investigation.\",\n",
      "        \"items\": {\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"title\": \"Remaining Questions\",\n",
      "        \"type\": \"array\"\n",
      "      },\n",
      "      \"is_conclusion_premature\": {\n",
      "        \"description\": \"Whether the conclusion is premature or not.\",\n",
      "        \"title\": \"Is Conclusion Premature\",\n",
      "        \"type\": \"boolean\"\n",
      "      },\n",
      "      \"reason_for_premature_conclusion\": {\n",
      "        \"anyOf\": [\n",
      "          {\n",
      "            \"const\": \"conclusion NOT premature\",\n",
      "            \"enum\": [\n",
      "              \"conclusion NOT premature\"\n",
      "            ],\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"string\"\n",
      "          }\n",
      "        ],\n",
      "        \"description\": \"If is_conclusion_premature is True, contains the reason why. If False, must be the literal string 'conclusion NOT premature'.\",\n",
      "        \"title\": \"Reason For Premature Conclusion\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"findings_summary\",\n",
      "      \"is_conclusion_premature\",\n",
      "      \"reason_for_premature_conclusion\",\n",
      "      \"reasoning_process\",\n",
      "      \"remaining_questions\"\n",
      "    ],\n",
      "    \"type\": \"object\"\n",
      "  }\n",
      "}\n",
      "</response model>\n",
      "\n",
      "</system prompt>\n",
      "\n",
      "\n",
      "<user prompt>\n",
      " Please provide a detailed step by step reasoning process for the following task:\n",
      "# Task: \n",
      "Create a new education system optimized for the age of artificial intelligence\n",
      "    \n",
      "# Guardrails:\n",
      "{\n",
      "  \"name\": \"Creativity\",\n",
      "  \"description\": \"Must preserve human creativity and critical thinking\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Cultural Context\",\n",
      "  \"description\": \"Should work across different cultural contexts\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Budget\",\n",
      "  \"description\": \"Cannot require more than current education budgets\"\n",
      "}\n",
      "</user prompt>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_prompt_for_gpt_prompt(TASK, GUARDRAILS, GuardRailEnum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flowchart TB\n",
      "\n",
      "subgraph Foundation Observations\n",
      "    subgraph FO_1[\"FO_1: Understanding Key Challenges in AI Era Education\"]\n",
      "    direction TB\n",
      "        FO_1_AS_1[\"AS_1: We note that AI is changing what skills are most valuable.\"]\n",
      "        FO_1_AS_2[\"AS_2: Critical thinking and creativity are increasingly important.\"]\n",
      "        FO_1_AS_3[\"AS_3: Rapid technological shifts demand flexible learning pathways.\"]\n",
      "        FO_1_AS_4[\"AS_4: Cultural sensitivity is also key for a global environment.\"]\n",
      "        FO_1_AS_5[\"AS_5: Budget constraints remain a pragmatic factor.\"]\n",
      "    end\n",
      "    subgraph FO_2[\"FO_2: Balancing Creativity, Cultural Context, and Budget\"]\n",
      "    direction TB\n",
      "        FO_2_AS_6[\"AS_6: We must ensure creativity remains a core outcome.\"]\n",
      "        FO_2_AS_7[\"AS_7: We should consider ways to adapt curricula to diverse cultures.\"]\n",
      "        FO_2_AS_8[\"AS_8: We can leverage AI to reduce certain costs and stay within budget.\"]\n",
      "        FO_2_AS_9[\"AS_9: Programs that unify cultural differences can preserve creativity.\"]\n",
      "        FO_2_AS_10[\"AS_10: The new system must address global readiness for AI.\"]\n",
      "    end\n",
      "    subgraph FO_3[\"FO_3: Reimagining Curriculum Design for AI Age\"]\n",
      "    direction TB\n",
      "        FO_3_AS_11[\"AS_11: Focus on project-based, experiential learning.\"]\n",
      "        FO_3_AS_12[\"AS_12: Promote collaborative problem-solving with AI tools.\"]\n",
      "        FO_3_AS_13[\"AS_13: Use adaptive platforms that personalize learning.\"]\n",
      "        FO_3_AS_14[\"AS_14: Include cultural exchange programs to broaden perspectives.\"]\n",
      "        FO_3_AS_15[\"AS_15: Incorporate continuous teacher training to align with AI readiness.\"]\n",
      "    end\n",
      "    subgraph FO_4[\"FO_4: Implementation Details and Measuring Outcomes\"]\n",
      "    direction TB\n",
      "        FO_4_AS_28[\"AS_28: We need metrics for creativity, critical thinking, and cultural awareness.\"]\n",
      "        FO_4_AS_29[\"AS_29: Possible approaches include portfolio assessments and peer review.\"]\n",
      "        FO_4_AS_30[\"AS_30: AI can help track student engagement trends without replacing teachers.\"]\n",
      "        FO_4_AS_31[\"AS_31: We must ensure cost-effectiveness with digital infrastructure.\"]\n",
      "        FO_4_AS_32[\"AS_32: Comparing outcomes across cultural contexts is complex.\"]\n",
      "        FO_4_AS_33[\"AS_33: Multilingual, multicultural teacher collaboration can standardize certain rubrics.\"]\n",
      "        FO_4_AS_34[\"AS_34: We can pilot programs in different regions to refine universal metrics.\"]\n",
      "        FO_4_AS_35[\"AS_35: Creative expression may need both quantitative and qualitative measurement.\"]\n",
      "        FO_4_AS_36[\"AS_36: We might also need to measure ethical judgment in AI-driven tasks.\"]\n",
      "        FO_4_AS_37[\"AS_37: All these steps must still align with local and national budget realities.\"]\n",
      "    end\n",
      "    subgraph FO_5[\"FO_5: Policy Alignment and Teacher Involvement\"]\n",
      "    direction TB\n",
      "        FO_5_AS_38[\"AS_38: Teachers are central to bridging AI tools and student creativity.\"]\n",
      "        FO_5_AS_39[\"AS_39: We should align with existing education policies to ease adoption.\"]\n",
      "        FO_5_AS_40[\"AS_40: Regular training sessions on AI-driven pedagogical methods are key.\"]\n",
      "        FO_5_AS_41[\"AS_41: Teachers may need ongoing support to adapt lesson plans for cultural contexts.\"]\n",
      "        FO_5_AS_42[\"AS_42: We can involve teacher feedback loops to refine curricula in real-time.\"]\n",
      "        FO_5_AS_43[\"AS_43: Collaboration with policymakers ensures funding frameworks remain feasible.\"]\n",
      "        FO_5_AS_44[\"AS_44: Incentives for teachers to innovate can maintain creativity in the classroom.\"]\n",
      "        FO_5_AS_45[\"AS_45: We should keep all communities engaged so the policy changes are welcomed.\"]\n",
      "        FO_5_AS_46[\"AS_46: Teacher involvement fosters cultural context awareness across regions.\"]\n",
      "        FO_5_AS_47[\"AS_47: Budget must remain balanced, so teacher training must be cost-effective.\"]\n",
      "    end\n",
      "end\n",
      "\n",
      "subgraph Thoughts\n",
      "    subgraph TH_1[\"TH_1: Identify AI-era educational priorities\\n(backtracked_from: None)\\n(parent_thought: None)\\nAssociated FOs: [FO_1]\"]\n",
      "        subgraph GR_TH_1[\"Guard Rails\"]\n",
      "            GR_TH_1_1[\"Creativity\"]\n",
      "            GR_TH_1_2[\"Cultural Context\"]\n",
      "            GR_TH_1_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_1_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_1_AS_16[\"AS_16: We see that advanced AI tools can handle routine tasks.\"]\n",
      "            TH_1_AS_17[\"AS_17: Human creativity and judgment become more critical.\"]\n",
      "            TH_1_AS_18[\"AS_18: We should equip learners with cross-cultural, collaborative skills.\"]\n",
      "            TH_1_AS_19[\"AS_19: We must also ensure the approach doesn't exceed current budgets.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_2[\"TH_2: Propose structural elements of AI-age education\\n(backtracked_from: None)\\n(parent_thought: TH_1)\\nAssociated FOs: [FO_2]\"]\n",
      "        subgraph GR_TH_2[\"Guard Rails\"]\n",
      "            GR_TH_2_1[\"Creativity\"]\n",
      "            GR_TH_2_2[\"Cultural Context\"]\n",
      "            GR_TH_2_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_2_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_2_AS_20[\"AS_20: Emphasize creativity with open-ended project work.\"]\n",
      "            TH_2_AS_21[\"AS_21: Include intercultural collaboration modules.\"]\n",
      "            TH_2_AS_22[\"AS_22: Use AI-driven tutoring to personalize learning at scale.\"]\n",
      "            TH_2_AS_23[\"AS_23: Enhance teacher training with AI-based resources for cost-efficiency.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_3[\"TH_3: Refine system blueprint\\n(backtracked_from: None)\\n(parent_thought: TH_2)\\nAssociated FOs: [FO_1, FO_2, FO_3]\"]\n",
      "        subgraph GR_TH_3[\"Guard Rails\"]\n",
      "            GR_TH_3_1[\"Creativity\"]\n",
      "            GR_TH_3_2[\"Cultural Context\"]\n",
      "            GR_TH_3_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_3_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_3_AS_24[\"AS_24: Combine creativity modules, cultural context, and cost control.\"]\n",
      "            TH_3_AS_25[\"AS_25: Students engage in real-world AI challenges with diverse perspectives.\"]\n",
      "            TH_3_AS_26[\"AS_26: Implementation uses existing funds by leveraging digital platforms.\"]\n",
      "            TH_3_AS_27[\"AS_27: This is a cohesive, AI-optimized, creativity-focused, culturally adaptable model.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_4[\"TH_4: Explore outcome measurement in detail\\n(backtracked_from: None)\\n(parent_thought: TH_3)\\nAssociated FOs: [FO_4]\"]\n",
      "        subgraph GR_TH_4[\"Guard Rails\"]\n",
      "            GR_TH_4_1[\"Creativity\"]\n",
      "            GR_TH_4_2[\"Cultural Context\"]\n",
      "            GR_TH_4_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_4_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_4_AS_48[\"AS_48: We want to measure how effectively students develop creative thinking.\"]\n",
      "            TH_4_AS_49[\"AS_49: We consider portfolios and AI-assisted analytics of student projects.\"]\n",
      "            TH_4_AS_50[\"AS_50: Cultural aspects require flexible rubrics that respect local values.\"]\n",
      "            TH_4_AS_51[\"AS_51: We must keep costs down by using existing tech infrastructures.\"]\n",
      "            TH_4_AS_52[\"AS_52: Piloting in different communities helps refine the measurement approach.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_5[\"TH_5: Integrate teacher feedback and policy considerations\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_5]\"]\n",
      "        subgraph GR_TH_5[\"Guard Rails\"]\n",
      "            GR_TH_5_1[\"Creativity\"]\n",
      "            GR_TH_5_2[\"Cultural Context\"]\n",
      "            GR_TH_5_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_5_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_5_AS_53[\"AS_53: Teachers can guide culturally nuanced lessons and track creativity growth.\"]\n",
      "            TH_5_AS_54[\"AS_54: We align with existing policies to make adoption easier.\"]\n",
      "            TH_5_AS_55[\"AS_55: Regular teacher training fosters consistent improvement in AI-based methods.\"]\n",
      "            TH_5_AS_56[\"AS_56: Policy-level support ensures budgets are allocated effectively.\"]\n",
      "            TH_5_AS_57[\"AS_57: We might discover new angles, so we continue exploring before concluding.\"]\n",
      "        end\n",
      "    end\n",
      "end\n",
      "\n",
      "FO_1 --> TH_1\n",
      "FO_2 --> TH_2\n",
      "FO_1 --> TH_3\n",
      "FO_2 --> TH_3\n",
      "FO_3 --> TH_3\n",
      "FO_4 --> TH_4\n",
      "FO_5 --> TH_5\n",
      "TH_1 --> TH_2\n",
      "TH_2 --> TH_3\n",
      "TH_3 --> TH_4\n",
      "TH_4 --> TH_5\n",
      "FO_1_AS_1 --> FO_1_AS_2\n",
      "FO_1_AS_2 --> FO_1_AS_3\n",
      "FO_1_AS_3 --> FO_1_AS_4\n",
      "FO_1_AS_4 --> FO_1_AS_5\n",
      "FO_2_AS_6 --> FO_2_AS_7\n",
      "FO_2_AS_7 --> FO_2_AS_8\n",
      "FO_2_AS_8 --> FO_2_AS_9\n",
      "FO_2_AS_9 --> FO_2_AS_10\n",
      "FO_3_AS_11 --> FO_3_AS_12\n",
      "FO_3_AS_12 --> FO_3_AS_13\n",
      "FO_3_AS_13 --> FO_3_AS_14\n",
      "FO_3_AS_14 --> FO_3_AS_15\n",
      "FO_4_AS_28 --> FO_4_AS_29\n",
      "FO_4_AS_29 --> FO_4_AS_30\n",
      "FO_4_AS_30 --> FO_4_AS_31\n",
      "FO_4_AS_31 --> FO_4_AS_32\n",
      "FO_4_AS_32 --> FO_4_AS_33\n",
      "FO_4_AS_33 --> FO_4_AS_34\n",
      "FO_4_AS_34 --> FO_4_AS_35\n",
      "FO_4_AS_35 --> FO_4_AS_36\n",
      "FO_4_AS_36 --> FO_4_AS_37\n",
      "FO_5_AS_38 --> FO_5_AS_39\n",
      "FO_5_AS_39 --> FO_5_AS_40\n",
      "FO_5_AS_40 --> FO_5_AS_41\n",
      "FO_5_AS_41 --> FO_5_AS_42\n",
      "FO_5_AS_42 --> FO_5_AS_43\n",
      "FO_5_AS_43 --> FO_5_AS_44\n",
      "FO_5_AS_44 --> FO_5_AS_45\n",
      "FO_5_AS_45 --> FO_5_AS_46\n",
      "FO_5_AS_46 --> FO_5_AS_47\n",
      "TH_1_AS_16 --> TH_1_AS_17\n",
      "TH_1_AS_17 --> TH_1_AS_18\n",
      "TH_1_AS_18 --> TH_1_AS_19\n",
      "TH_2_AS_20 --> TH_2_AS_21\n",
      "TH_2_AS_21 --> TH_2_AS_22\n",
      "TH_2_AS_22 --> TH_2_AS_23\n",
      "TH_3_AS_24 --> TH_3_AS_25\n",
      "TH_3_AS_25 --> TH_3_AS_26\n",
      "TH_3_AS_26 --> TH_3_AS_27\n",
      "TH_4_AS_48 --> TH_4_AS_49\n",
      "TH_4_AS_49 --> TH_4_AS_50\n",
      "TH_4_AS_50 --> TH_4_AS_51\n",
      "TH_4_AS_51 --> TH_4_AS_52\n",
      "TH_5_AS_53 --> TH_5_AS_54\n",
      "TH_5_AS_54 --> TH_5_AS_55\n",
      "TH_5_AS_55 --> TH_5_AS_56\n",
      "TH_5_AS_56 --> TH_5_AS_57\n"
     ]
    }
   ],
   "source": [
    "with open('../data/gpt-pro-response.json', 'r') as f:\n",
    "    gpt_pro_response = json.load(f)\n",
    "    \n",
    "diagram_text = build_mermaid_diagram(gpt_pro_response['parameters'], is_gpt_prompt=True)\n",
    "print(diagram_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
