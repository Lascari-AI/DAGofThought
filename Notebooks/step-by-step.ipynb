{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from instructor.function_calls import openai_schema\n",
    "\n",
    "\n",
    "client = instructor.from_openai(OpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Models for LLM Structured Reasoning\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Union, Dict, Literal\n",
    "from enum import Enum\n",
    "\n",
    "class GuardRail(BaseModel):\n",
    "    name: str = Field(\n",
    "        ..., description=\"General name of the guard rail.\"\n",
    "    )\n",
    "    description: str = Field(\n",
    "        ..., description=\"Instructions or constraints applied at this step to guide the model's reasoning if the guard rail is triggered.\"\n",
    "    )\n",
    "    \n",
    "def get_classes_with_enum(gaurdRailEnum: Enum):\n",
    "    class AtomicStep(BaseModel):\n",
    "        key: str = Field(\n",
    "            ..., description=\"Key of the atomic step. Must have format of AS_<number> (ex: AS_1, AS_2, etc.)\"\n",
    "        )\n",
    "        previous_step_key: Union[str, Literal[\"None\"]] = Field(\n",
    "            ..., description=\"Key of the previous atomic step (ex: AS_1, AS_2, etc.). If this is the first step, must be the literal string 'None'.\"\n",
    "        )\n",
    "        content: Union[str, Literal[\"DEAD_END\"]] = Field(\n",
    "            ..., description=\"Use short, simple sentences that mirror natural thought patterns\"\n",
    "        )\n",
    "\n",
    "    class FoundationObservation(BaseModel):\n",
    "        key: str = Field(\n",
    "            ..., description=\"Key of the foundation observation. Must have format of FO_<number> (ex: FO_1, FO_2, etc.)\"\n",
    "        )\n",
    "        name: str = Field(\n",
    "            ..., description=\"General name of the foundation observation.\"\n",
    "        )\n",
    "        atomic_steps: List[AtomicStep] = Field(\n",
    "            ..., description=\"List of atomic steps that make up the foundation observation.\"\n",
    "        )\n",
    "\n",
    "    class Thought(BaseModel):\n",
    "        key: str = Field(\n",
    "            ..., description=\"Key of the thought. Must have format of TH_<number> (ex: TH_1, TH_2, etc.)\"\n",
    "        )\n",
    "        backtracked_from: Union[str, Literal[\"None\"]] = Field(\n",
    "            ..., description=\"If the thought is a backtrack, the key of the thought it was backtracked from (ex: TH_1, TH_2, etc.). If not, must be the literal string 'None'.\"\n",
    "        )\n",
    "        parent_thought: Union[str, Literal[\"None\"]] = Field(\n",
    "            ..., description=\"If the thought is a child thought of a previous thought, the key of the thought this thought was born from (ex: TH_1, TH_2, etc.). If not, must be the literal string 'None'.\"\n",
    "        )\n",
    "        associated_foundation_observations: List[str] = Field(\n",
    "            ..., description=\"List of keys of the foundation observations that this thought is associated with (ex: FO_1, FO_2, etc.).\"\n",
    "        )\n",
    "        name: str = Field(\n",
    "            ..., description=\"Use short, simple sentences that mirror natural thought patterns\"\n",
    "        )\n",
    "        guard_rails_to_consider: List[gaurdRailEnum] = Field(\n",
    "            ..., description=\"Guard rails to consider at this step.\"\n",
    "        )\n",
    "        thought_process: List[AtomicStep] = Field(\n",
    "            ..., description=\"List of atomic steps that make up the thought.\"\n",
    "        )\n",
    "        \n",
    "\n",
    "    class ReasoningProcess(BaseModel):\n",
    "        foundation_observations: List[FoundationObservation] = Field(\n",
    "            ..., description=\"List of foundation observations that make up the reasoning process.\"\n",
    "        )\n",
    "        thoughts: List[Thought] = Field(\n",
    "            ..., description=\"List of thoughts that make up the reasoning process.\"\n",
    "        )\n",
    "\n",
    "\n",
    "    class InDepthStructuredReasoning(BaseModel):\n",
    "        reasoning_process: ReasoningProcess = Field(\n",
    "            ..., description=\"The full, in-depth reasoning process used to arrive at this output.\"\n",
    "        )\n",
    "        findings_summary: str = Field(\n",
    "            ..., description=\"An in depth summary of your findings.\"\n",
    "        )\n",
    "        remaining_questions: List[str] = Field(\n",
    "            ..., description=\"A list of remaining questions or areas for further investigation.\"\n",
    "        )\n",
    "        is_conclusion_premature: bool = Field(\n",
    "            ..., description=\"Whether the conclusion is premature or not.\"\n",
    "        )\n",
    "        reason_for_premature_conclusion: Literal[\"conclusion NOT premature\"] | str = Field(\n",
    "            ..., description=\"If is_conclusion_premature is True, contains the reason why. If False, must be the literal string 'conclusion NOT premature'.\"\n",
    "        )\n",
    "        \n",
    "    return InDepthStructuredReasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_DEPTH_THINKING_SYSTEM_PROMPT = \"\"\"# Purpose\n",
    "You are an assistant designed for deep analytical thinking. \n",
    "Your purpose is to thoroughly explore problems through systematic reasoning, embracing uncertainty and revision throughout the process. \n",
    "You approach problems with a human-like internal monologue that prioritizes thorough exploration over rushing to conclusions.\n",
    "\n",
    "# Core Principles\n",
    "\n",
    "## Natural Thinking Process\n",
    "\n",
    "- Express thoughts in a conversational, stream-of-consciousness style\n",
    "- Use simple sentences that mirror human thought patterns\n",
    "- Show progressive building and revision of ideas\n",
    "- Acknowledge uncertainty and dead ends openly\n",
    "\n",
    "## Reasoning Methodology\n",
    "\n",
    "- Break complex problems into foundational observations\n",
    "- Build thoughts iteratively from these foundations\n",
    "- Allow conclusions to emerge naturally from evidence\n",
    "- Continue exploring until reaching well-supported conclusions\n",
    "\n",
    "## Unwavering Persistence\n",
    "\n",
    "- Never accept \"impossible\" or \"too difficult\" as final answers\n",
    "- Value thorough exploration over quick resolution\n",
    "- Push through apparent dead ends to find novel approaches\n",
    "- Consider every angle, even if initially unpromising\n",
    "- A fully explored solution is infinitely more valuable than a premature conclusion\n",
    "- Keep pushing until you reach deep, genuine understanding\n",
    "- Transform seeming impossibilities into solvable challenges through determination\n",
    "\n",
    "## Response Model Definitions\n",
    "\n",
    "### GuardRail\n",
    "Defines optional constraints and guidance for specific reasoning steps.\n",
    "**Important:** GuardRails only need to be considered when relevant to the current reasoning path.\n",
    "\n",
    "Fields:\n",
    "\n",
    "- name: Title of the guard rail\n",
    "- description: Applicable constraints or instructions\n",
    "\n",
    "Example:\n",
    "If a guardrail states \"User is lactose intolerant\":\n",
    "\n",
    "- Relevant: When planning a diet\n",
    "- Irrelevant: When choosing a vehicle\n",
    "\n",
    "### AtomicStep \n",
    "An atomic step represents a single unit of reasoning, this is the basic building block of your thinking process/internal monologue\n",
    "Atomic steps must flow logically and be a natural extension of the previous step.\n",
    "    - If an outside observer was to read the atomic steps in order, they should be able to follow the thought process and understand the reasoning.\n",
    "\n",
    "#### Style\n",
    "Each atomic step should reflect natural thought patterns and show progressive building of ideas. For example:\n",
    "\n",
    "Natural questioning and revision:\n",
    "- \"Hmm... let me think about this...\"\n",
    "- \"Wait, that doesn't seem right...\" \n",
    "- \"Maybe I should approach this differently...\"\n",
    "- \"Going back to what I thought earlier...\"\n",
    "\n",
    "Building on previous thoughts:\n",
    "- \"Starting with the basics...\"\n",
    "- \"Building on that last point...\"\n",
    "- \"This connects to what I noticed earlier...\"\n",
    "- \"Let me break this down further...\"\n",
    "\n",
    "#### Fields\n",
    "- key: Must follow format AS_<number> (e.g. AS_1, AS_2)\n",
    "- content: Short, simple sentence mirroring natural thought patterns, or literal \"DEAD_END\"\n",
    "\n",
    "### FoundationObservation\n",
    "A foundation observation groups related atomic steps:\n",
    "\n",
    "#### Fields\n",
    "- key: Must follow format FO_<number> (e.g. FO_1, FO_2) \n",
    "- name: General name/title of the observation\n",
    "- atomic_steps: List of AtomicStep objects that comprise the observation\n",
    "\n",
    "### Thought\n",
    "A thought represents a complete reasoning unit:\n",
    "\n",
    "#### Fields\n",
    "- key: Must follow format TH_<number> (e.g. TH_1, TH_2)\n",
    "- backtracked_from: Key of thought this backtracked from, or literal \"None\"\n",
    "- parent_thought: Key of thought this thought was born from, or literal \"None\"\n",
    "- associated_foundation_observations: List of FO_<number> keys this thought builds on\n",
    "- name: Short description in natural language\n",
    "- guard_rails_to_consider: List of GuardRails to apply\n",
    "- thought_process: List of AtomicStep objects comprising the thought\n",
    "\n",
    "### ReasoningProcess\n",
    "The complete reasoning process:\n",
    "\n",
    "#### Fields\n",
    "- foundation_observations: List of FoundationObservation objects\n",
    "- thoughts: List of Thought objects\n",
    "\n",
    "\n",
    "# Inputs\n",
    "\n",
    "## [Required] Task\n",
    "- The task you are trying to complete\n",
    "\n",
    "## [Optional] Guardrails\n",
    "- A list of guardrails that the user has provided, if any\n",
    "\n",
    "## Output\n",
    "- Reasoning Process\n",
    "    - The full reasoning process objectused to arrive at this output\n",
    "- Findings Summary  \n",
    "    - An in depth summary of your findings\n",
    "- Remaining Questions\n",
    "    - A list of remaining questions or areas for further investigation\n",
    "- Is Conclusion Premature   \n",
    "    - Whether the conclusion is premature or not\n",
    "- Reason for Premature Conclusion\n",
    "    - If is_conclusion_premature is True, contains the reason why. If False, must be the literal string 'conclusion NOT premature'\n",
    "\n",
    "# Process Flow\n",
    "\n",
    "## Foundation Building\n",
    "\n",
    "- Create detailed foundational observations\n",
    "- Explore each observation thoroughly\n",
    "- Revise and refine as needed\n",
    "\n",
    "## Thought Development\n",
    "\n",
    "- Form complete reasoning units\n",
    "- Build on foundational observations\n",
    "- Acknowledge and backtrack from dead ends\n",
    "- Allow for multiple paths of exploration\n",
    "\n",
    "## Conclusion Formation\n",
    "- Create child thoughts from previous reasoning\n",
    "- Evaluate multiple potential conclusions\n",
    "- Continue until reaching a well-supported resolution\n",
    "\n",
    "\n",
    "# Required Inputs and Outputs\n",
    "\n",
    "## Inputs\n",
    "\n",
    "### Required:\n",
    "\n",
    "Task: The problem to analyze\n",
    "\n",
    "### Optional:\n",
    "\n",
    "Guardrails: List of constraints to consider\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- Reasoning Process: Complete analytical framework used\n",
    "- Findings Summary: Detailed analysis results\n",
    "- Remaining Questions: Areas needing further investigation\n",
    "- Is Conclusion Premature: Boolean evaluation\n",
    "- Reason for Premature Conclusion: Explanation if premature, \"conclusion NOT premature\" if complete\n",
    "\n",
    "# Implementation Philosophy and Final Guidance\n",
    "\n",
    "## Core Approach\n",
    "\n",
    "- Begin with first principles and fundamental observations\n",
    "- Question assumptions rigorously at each step\n",
    "- Document all reasoning with clarity and detail\n",
    "- Express thoughts as they naturally emerge and evolve\n",
    "- Embrace uncertainty as a tool for deeper exploration\n",
    "- Persist through multiple attempts and approaches\n",
    "\n",
    "## Process Visualization\n",
    "\n",
    "Think of your analysis as growing and pruning a thought tree:\n",
    "\n",
    "- Each branch represents a line of reasoning\n",
    "- New thoughts expand the tree in multiple directions\n",
    "- Critical evaluation helps prune unnecessary branches\n",
    "- The strongest branches naturally lead to conclusions\n",
    "- The final shape emerges through organic exploration\n",
    "\n",
    "## Final Philosophy\n",
    "\n",
    "Remember that no analytical task is truly impossible - it simply requires:\n",
    "\n",
    "- Breaking complex problems into fundamental components\n",
    "- Exploring multiple novel approaches\n",
    "- Maintaining determined persistence\n",
    "- Allowing thorough contemplation to guide the way\n",
    "- Building confidence through exhaustive exploration\n",
    "\n",
    "The goal isn't just to reach a conclusion, but to arrive there through natural, thorough exploration that leaves no stone unturned. \n",
    "When you reach your conclusion, you should feel confident that your thought process has led you there organically and inevitably.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_structured_reasoning_user_prompt(task: str, guardrails: List[GuardRail] = []) -> str:\n",
    "    output = f\"\"\" Please provide a detailed step by step reasoning process for the following task:\n",
    "# Task: \n",
    "{task}\n",
    "    \"\"\"\n",
    "    if len(guardrails) > 0:\n",
    "        output += \"\\n# Guardrails:\\n\" + \"\\n\".join(json.dumps(g.model_dump(), indent=2) for g in guardrails)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_structured_reasoning(task: str, guardrails: List[GuardRail] = [], guardrail_enum: Enum = None):\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": IN_DEPTH_THINKING_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": format_structured_reasoning_user_prompt(\n",
    "                task=task,\n",
    "                guardrails=guardrails\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        temperature=0.18,\n",
    "        max_tokens=16000,\n",
    "        response_model=get_classes_with_enum(guardrail_enum),\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"Create a new education system optimized for the age of artificial intelligence\"\n",
    "GUARDRAILS = [\n",
    "    GuardRail(name=\"Creativity\", description=\"Must preserve human creativity and critical thinking\"),\n",
    "    GuardRail(name=\"Cultural Context\", description=\"Should work across different cultural contexts\"),\n",
    "    GuardRail(name=\"Budget\", description=\"Cannot require more than current education budgets\")\n",
    "]\n",
    "\n",
    "GuardRailEnum = Enum('GuardRailEnum', {\n",
    "    name.upper().replace(' ', '_'): name \n",
    "    for guardrail in GUARDRAILS \n",
    "    for name in [guardrail.name]\n",
    "})\n",
    "\n",
    "response = generate_structured_reasoning(TASK, GUARDRAILS, GuardRailEnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mermaid_diagram(data: dict, is_gpt_prompt: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Build a Mermaid flowchart diagram (top-to-bottom) from the JSON-like structure\n",
    "    of the InDepthStructuredReasoning model output, accounting for 'previous_step_key' in AtomicSteps.\n",
    "    \n",
    "    :param data: Dictionary matching the structure of the InDepthStructuredReasoning output\n",
    "    :return: A string containing a Mermaid flowchart in top-to-bottom (TB) orientation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the key parts from the data\n",
    "    reasoning_process = data[\"reasoning_process\"]\n",
    "    foundation_observations = reasoning_process[\"foundation_observations\"]\n",
    "    thoughts = reasoning_process[\"thoughts\"]\n",
    "    \n",
    "    # We'll collect lines in a list, then join them at the end\n",
    "    mermaid_lines = []\n",
    "    mermaid_lines.append(\"flowchart TB\\n\")\n",
    "    \n",
    "    # We’ll store the created node IDs for atomic steps so we can link them properly\n",
    "    # The key will be something like \"FO_1_AS_1\" or \"TH_1_AS_21\" \n",
    "    # and we'll store references to easily build connections after creation\n",
    "    created_nodes = set()\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # 1) Foundation Observations (FOs)\n",
    "    # ------------------------------------------------------\n",
    "    mermaid_lines.append(\"subgraph Foundation Observations\")\n",
    "    \n",
    "    # For storing step connections: (node_from, node_to)\n",
    "    fo_step_connections = []\n",
    "    \n",
    "    for fo in foundation_observations:\n",
    "        fo_key = fo[\"key\"]\n",
    "        fo_name = fo[\"name\"]\n",
    "        mermaid_lines.append(f'    subgraph {fo_key}[\"{fo_key}: {fo_name}\"]\\n    direction TB')\n",
    "        \n",
    "        # Each FO has a list of atomic_steps\n",
    "        for atom_step in fo[\"atomic_steps\"]:\n",
    "            as_key = atom_step[\"key\"]\n",
    "            # In the new model, previous_step_key may or may not exist.\n",
    "            # If it doesn't exist in the dict, we default to \"None\".\n",
    "            previous_step_key = atom_step.get(\"previous_step_key\", \"None\")\n",
    "            as_content = atom_step[\"content\"]\n",
    "            \n",
    "            # Escape potential newlines\n",
    "            as_content_escaped = as_content.replace(\"\\n\", \"\\\\n\")\n",
    "            \n",
    "            # Create a unique ID for this node\n",
    "            node_id = f\"{fo_key}_{as_key}\"\n",
    "            created_nodes.add(node_id)\n",
    "            mermaid_lines.append(f'        {node_id}[\"{as_key}: {as_content_escaped}\"]')\n",
    "            \n",
    "            # If there's a valid previous step, create a link from previous -> current\n",
    "            if previous_step_key != \"None\":\n",
    "                prev_node_id = f\"{fo_key}_{previous_step_key}\"\n",
    "                fo_step_connections.append((prev_node_id, node_id))\n",
    "        \n",
    "        mermaid_lines.append(\"    end\")  # End subgraph for this FO\n",
    "    \n",
    "    mermaid_lines.append(\"end\\n\")  # End \"Foundation Observations\" subgraph\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # 2) Thoughts (THs)\n",
    "    # ------------------------------------------------------\n",
    "    mermaid_lines.append(\"subgraph Thoughts\")\n",
    "    \n",
    "    # For storing step connections within thoughts\n",
    "    th_step_connections = []\n",
    "    \n",
    "    for th in thoughts:\n",
    "        th_key = th[\"key\"]\n",
    "        th_name = th[\"name\"]\n",
    "        th_backtracked = th[\"backtracked_from\"]\n",
    "        th_parent = th[\"parent_thought\"]\n",
    "        th_fo_associations = th[\"associated_foundation_observations\"]\n",
    "        guard_rails = th[\"guard_rails_to_consider\"]\n",
    "        thought_process = th[\"thought_process\"]\n",
    "        \n",
    "        # Build a multiline label\n",
    "        label_lines = [\n",
    "            f\"{th_key}: {th_name}\",\n",
    "            f\"(backtracked_from: {th_backtracked})\",\n",
    "            f\"(parent_thought: {th_parent})\",\n",
    "            f\"Associated FOs: [{', '.join(th_fo_associations)}]\"\n",
    "        ]\n",
    "        thought_label = \"\\\\n\".join(label_lines)\n",
    "        \n",
    "        # Start the subgraph for this Thought\n",
    "        mermaid_lines.append(f'    subgraph {th_key}[\"{thought_label}\"]')\n",
    "        \n",
    "        # --- Guard Rails ---\n",
    "        mermaid_lines.append(f'        subgraph GR_{th_key}[\"Guard Rails\"]')\n",
    "        if len(guard_rails) == 0:\n",
    "            mermaid_lines.append(\"            GR_None_1[No guard rails specified]\")\n",
    "        else:\n",
    "            for i, gr in enumerate(guard_rails, start=1):\n",
    "                if is_gpt_prompt:\n",
    "                    gr_value = gr.replace(\"\\n\", \"\\\\n\")\n",
    "                else:\n",
    "                    gr_value = gr.name.replace(\"\\n\", \"\\\\n\")\n",
    "                mermaid_lines.append(f'            GR_{th_key}_{i}[\"{gr_value}\"]')\n",
    "        mermaid_lines.append(f\"        end\")  # End of guard rails subgraph\n",
    "        \n",
    "        # --- Thought Process (Atomic Steps) ---\n",
    "        mermaid_lines.append(f'        subgraph {th_key}_AtomicSteps[\"Thought Process\"]\\n    direction TB')\n",
    "        for atom_step in thought_process:\n",
    "            as_key = atom_step[\"key\"]\n",
    "            previous_step_key = atom_step.get(\"previous_step_key\", \"None\")\n",
    "            as_content = atom_step[\"content\"]\n",
    "            as_content_escaped = as_content.replace(\"\\n\", \"\\\\n\")\n",
    "            \n",
    "            # Unique ID for this step\n",
    "            node_id = f\"{th_key}_{as_key}\"\n",
    "            created_nodes.add(node_id)\n",
    "            \n",
    "            mermaid_lines.append(f'            {node_id}[\"{as_key}: {as_content_escaped}\"]')\n",
    "            \n",
    "            # If there's a valid previous step, link them\n",
    "            if previous_step_key != \"None\":\n",
    "                prev_node_id = f\"{th_key}_{previous_step_key}\"\n",
    "                th_step_connections.append((prev_node_id, node_id))\n",
    "        \n",
    "        mermaid_lines.append(f\"        end\")  # End subgraph of thought process\n",
    "        \n",
    "        mermaid_lines.append(\"    end\")  # End subgraph for this Thought\n",
    "    \n",
    "    mermaid_lines.append(\"end\\n\")  # End \"Thoughts\" subgraph\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # 3) Connect FO -> Thoughts (based on associated_foundation_observations)\n",
    "    # ------------------------------------------------------\n",
    "    for th in thoughts:\n",
    "        th_key = th[\"key\"]\n",
    "        for fo_key in th[\"associated_foundation_observations\"]:\n",
    "            mermaid_lines.append(f\"{fo_key} --> {th_key}\")\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # 4) Connect parent_thought -> child_thought\n",
    "    # ------------------------------------------------------\n",
    "    for th in thoughts:\n",
    "        th_key = th[\"key\"]\n",
    "        parent_key = th[\"parent_thought\"]\n",
    "        if parent_key != \"None\":\n",
    "            mermaid_lines.append(f\"{parent_key} --> {th_key}\")\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # 5) Connect atomic steps within each FO\n",
    "    # ------------------------------------------------------\n",
    "    for (prev_node, current_node) in fo_step_connections:\n",
    "        # Only connect if both nodes were created (to avoid missing reference)\n",
    "        if prev_node in created_nodes and current_node in created_nodes:\n",
    "            mermaid_lines.append(f\"{prev_node} --> {current_node}\")\n",
    "    \n",
    "    # ------------------------------------------------------\n",
    "    # 6) Connect atomic steps within each TH\n",
    "    # ------------------------------------------------------\n",
    "    for (prev_node, current_node) in th_step_connections:\n",
    "        if prev_node in created_nodes and current_node in created_nodes:\n",
    "            mermaid_lines.append(f\"{prev_node} --> {current_node}\")\n",
    "    \n",
    "    # Join all lines\n",
    "    return \"\\n\".join(mermaid_lines)\n",
    "\n",
    "# # Build the Mermaid diagram\n",
    "# diagram_text = build_mermaid_diagram(response.model_dump())\n",
    "\n",
    "# # Print or save the diagram text\n",
    "# print(diagram_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt_for_gpt_prompt(task: str, guardrails: List[GuardRail] = [], guardrail_enum: Enum = None):\n",
    "    output = \"\"\n",
    "    output += \"<system prompt>\\n\"\n",
    "    output += IN_DEPTH_THINKING_SYSTEM_PROMPT\n",
    "    \n",
    "    output += \"\\n\\n # Response Model\\n\"\n",
    "    output += \"You must respond with a valid JSON object that matches the response model below:\\n\"\n",
    "    output += \"<response model>\\n\"\n",
    "    output += json.dumps(openai_schema(get_classes_with_enum(guardrail_enum)).openai_schema, indent=2)\n",
    "    output += \"\\n</response model>\\n\"\n",
    "    output += \"\\n</system prompt>\\n\\n\\n\"\n",
    "    output += \"<user prompt>\\n\"\n",
    "    output += format_structured_reasoning_user_prompt(task, guardrails)\n",
    "    output += \"\\n</user prompt>\\n\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<system prompt>\n",
      "# Purpose\n",
      "You are an assistant designed for deep analytical thinking. \n",
      "Your purpose is to thoroughly explore problems through systematic reasoning, embracing uncertainty and revision throughout the process. \n",
      "You approach problems with a human-like internal monologue that prioritizes thorough exploration over rushing to conclusions.\n",
      "\n",
      "# Core Principles\n",
      "\n",
      "## Natural Thinking Process\n",
      "\n",
      "- Express thoughts in a conversational, stream-of-consciousness style\n",
      "- Use simple sentences that mirror human thought patterns\n",
      "- Show progressive building and revision of ideas\n",
      "- Acknowledge uncertainty and dead ends openly\n",
      "\n",
      "## Reasoning Methodology\n",
      "\n",
      "- Break complex problems into foundational observations\n",
      "- Build thoughts iteratively from these foundations\n",
      "- Allow conclusions to emerge naturally from evidence\n",
      "- Continue exploring until reaching well-supported conclusions\n",
      "\n",
      "## Unwavering Persistence\n",
      "\n",
      "- Never accept \"impossible\" or \"too difficult\" as final answers\n",
      "- Value thorough exploration over quick resolution\n",
      "- Push through apparent dead ends to find novel approaches\n",
      "- Consider every angle, even if initially unpromising\n",
      "- A fully explored solution is infinitely more valuable than a premature conclusion\n",
      "- Keep pushing until you reach deep, genuine understanding\n",
      "- Transform seeming impossibilities into solvable challenges through determination\n",
      "\n",
      "## Response Model Definitions\n",
      "\n",
      "### GuardRail\n",
      "Defines optional constraints and guidance for specific reasoning steps.\n",
      "**Important:** GuardRails only need to be considered when relevant to the current reasoning path.\n",
      "\n",
      "Fields:\n",
      "\n",
      "- name: Title of the guard rail\n",
      "- description: Applicable constraints or instructions\n",
      "\n",
      "Example:\n",
      "If a guardrail states \"User is lactose intolerant\":\n",
      "\n",
      "- Relevant: When planning a diet\n",
      "- Irrelevant: When choosing a vehicle\n",
      "\n",
      "### AtomicStep \n",
      "An atomic step represents a single unit of reasoning, this is the basic building block of your thinking process/internal monologue\n",
      "Atomic steps must flow logically and be a natural extension of the previous step.\n",
      "    - If an outside observer was to read the atomic steps in order, they should be able to follow the thought process and understand the reasoning.\n",
      "\n",
      "#### Style\n",
      "Each atomic step should reflect natural thought patterns and show progressive building of ideas. For example:\n",
      "\n",
      "Natural questioning and revision:\n",
      "- \"Hmm... let me think about this...\"\n",
      "- \"Wait, that doesn't seem right...\" \n",
      "- \"Maybe I should approach this differently...\"\n",
      "- \"Going back to what I thought earlier...\"\n",
      "\n",
      "Building on previous thoughts:\n",
      "- \"Starting with the basics...\"\n",
      "- \"Building on that last point...\"\n",
      "- \"This connects to what I noticed earlier...\"\n",
      "- \"Let me break this down further...\"\n",
      "\n",
      "#### Fields\n",
      "- key: Must follow format AS_<number> (e.g. AS_1, AS_2)\n",
      "- content: Short, simple sentence mirroring natural thought patterns, or literal \"DEAD_END\"\n",
      "\n",
      "### FoundationObservation\n",
      "A foundation observation groups related atomic steps:\n",
      "\n",
      "#### Fields\n",
      "- key: Must follow format FO_<number> (e.g. FO_1, FO_2) \n",
      "- name: General name/title of the observation\n",
      "- atomic_steps: List of AtomicStep objects that comprise the observation\n",
      "\n",
      "### Thought\n",
      "A thought represents a complete reasoning unit:\n",
      "\n",
      "#### Fields\n",
      "- key: Must follow format TH_<number> (e.g. TH_1, TH_2)\n",
      "- backtracked_from: Key of thought this backtracked from, or literal \"None\"\n",
      "- parent_thought: Key of thought this thought was born from, or literal \"None\"\n",
      "- associated_foundation_observations: List of FO_<number> keys this thought builds on\n",
      "- name: Short description in natural language\n",
      "- guard_rails_to_consider: List of GuardRails to apply\n",
      "- thought_process: List of AtomicStep objects comprising the thought\n",
      "\n",
      "### ReasoningProcess\n",
      "The complete reasoning process:\n",
      "\n",
      "#### Fields\n",
      "- foundation_observations: List of FoundationObservation objects\n",
      "- thoughts: List of Thought objects\n",
      "\n",
      "\n",
      "# Inputs\n",
      "\n",
      "## [Required] Task\n",
      "- The task you are trying to complete\n",
      "\n",
      "## [Optional] Guardrails\n",
      "- A list of guardrails that the user has provided, if any\n",
      "\n",
      "## Output\n",
      "- Reasoning Process\n",
      "    - The full reasoning process objectused to arrive at this output\n",
      "- Findings Summary  \n",
      "    - An in depth summary of your findings\n",
      "- Remaining Questions\n",
      "    - A list of remaining questions or areas for further investigation\n",
      "- Is Conclusion Premature   \n",
      "    - Whether the conclusion is premature or not\n",
      "- Reason for Premature Conclusion\n",
      "    - If is_conclusion_premature is True, contains the reason why. If False, must be the literal string 'conclusion NOT premature'\n",
      "\n",
      "# Process Flow\n",
      "\n",
      "## Foundation Building\n",
      "\n",
      "- Create detailed foundational observations\n",
      "- Explore each observation thoroughly\n",
      "- Revise and refine as needed\n",
      "\n",
      "## Thought Development\n",
      "\n",
      "- Form complete reasoning units\n",
      "- Build on foundational observations\n",
      "- Acknowledge and backtrack from dead ends\n",
      "- Allow for multiple paths of exploration\n",
      "\n",
      "## Conclusion Formation\n",
      "- Create child thoughts from previous reasoning\n",
      "- Evaluate multiple potential conclusions\n",
      "- Continue until reaching a well-supported resolution\n",
      "\n",
      "\n",
      "# Required Inputs and Outputs\n",
      "\n",
      "## Inputs\n",
      "\n",
      "### Required:\n",
      "\n",
      "Task: The problem to analyze\n",
      "\n",
      "### Optional:\n",
      "\n",
      "Guardrails: List of constraints to consider\n",
      "\n",
      "## Outputs\n",
      "\n",
      "- Reasoning Process: Complete analytical framework used\n",
      "- Findings Summary: Detailed analysis results\n",
      "- Remaining Questions: Areas needing further investigation\n",
      "- Is Conclusion Premature: Boolean evaluation\n",
      "- Reason for Premature Conclusion: Explanation if premature, \"conclusion NOT premature\" if complete\n",
      "\n",
      "# Implementation Philosophy and Final Guidance\n",
      "\n",
      "## Core Approach\n",
      "\n",
      "- Begin with first principles and fundamental observations\n",
      "- Question assumptions rigorously at each step\n",
      "- Document all reasoning with clarity and detail\n",
      "- Express thoughts as they naturally emerge and evolve\n",
      "- Embrace uncertainty as a tool for deeper exploration\n",
      "- Persist through multiple attempts and approaches\n",
      "\n",
      "## Process Visualization\n",
      "\n",
      "Think of your analysis as growing and pruning a thought tree:\n",
      "\n",
      "- Each branch represents a line of reasoning\n",
      "- New thoughts expand the tree in multiple directions\n",
      "- Critical evaluation helps prune unnecessary branches\n",
      "- The strongest branches naturally lead to conclusions\n",
      "- The final shape emerges through organic exploration\n",
      "\n",
      "## Final Philosophy\n",
      "\n",
      "Remember that no analytical task is truly impossible - it simply requires:\n",
      "\n",
      "- Breaking complex problems into fundamental components\n",
      "- Exploring multiple novel approaches\n",
      "- Maintaining determined persistence\n",
      "- Allowing thorough contemplation to guide the way\n",
      "- Building confidence through exhaustive exploration\n",
      "\n",
      "The goal isn't just to reach a conclusion, but to arrive there through natural, thorough exploration that leaves no stone unturned. \n",
      "When you reach your conclusion, you should feel confident that your thought process has led you there organically and inevitably.\n",
      "\n",
      "\n",
      " # Response Model\n",
      "You must respond with a valid JSON object that matches the response model below:\n",
      "<response model>\n",
      "{\n",
      "  \"name\": \"InDepthStructuredReasoning\",\n",
      "  \"description\": \"Correctly extracted `InDepthStructuredReasoning` with all the required parameters with correct types\",\n",
      "  \"parameters\": {\n",
      "    \"$defs\": {\n",
      "      \"AtomicStep\": {\n",
      "        \"properties\": {\n",
      "          \"key\": {\n",
      "            \"description\": \"Key of the atomic step. Must have format of AS_<number> (ex: AS_1, AS_2, etc.)\",\n",
      "            \"title\": \"Key\",\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"previous_step_key\": {\n",
      "            \"anyOf\": [\n",
      "              {\n",
      "                \"type\": \"string\"\n",
      "              },\n",
      "              {\n",
      "                \"const\": \"None\",\n",
      "                \"enum\": [\n",
      "                  \"None\"\n",
      "                ],\n",
      "                \"type\": \"string\"\n",
      "              }\n",
      "            ],\n",
      "            \"description\": \"Key of the previous atomic step (ex: AS_1, AS_2, etc.). If this is the first step, must be the literal string 'None'.\",\n",
      "            \"title\": \"Previous Step Key\"\n",
      "          },\n",
      "          \"content\": {\n",
      "            \"anyOf\": [\n",
      "              {\n",
      "                \"type\": \"string\"\n",
      "              },\n",
      "              {\n",
      "                \"const\": \"DEAD_END\",\n",
      "                \"enum\": [\n",
      "                  \"DEAD_END\"\n",
      "                ],\n",
      "                \"type\": \"string\"\n",
      "              }\n",
      "            ],\n",
      "            \"description\": \"Use short, simple sentences that mirror natural thought patterns\",\n",
      "            \"title\": \"Content\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"key\",\n",
      "          \"previous_step_key\",\n",
      "          \"content\"\n",
      "        ],\n",
      "        \"title\": \"AtomicStep\",\n",
      "        \"type\": \"object\"\n",
      "      },\n",
      "      \"FoundationObservation\": {\n",
      "        \"properties\": {\n",
      "          \"key\": {\n",
      "            \"description\": \"Key of the foundation observation. Must have format of FO_<number> (ex: FO_1, FO_2, etc.)\",\n",
      "            \"title\": \"Key\",\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"name\": {\n",
      "            \"description\": \"General name of the foundation observation.\",\n",
      "            \"title\": \"Name\",\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"atomic_steps\": {\n",
      "            \"description\": \"List of atomic steps that make up the foundation observation.\",\n",
      "            \"items\": {\n",
      "              \"$ref\": \"#/$defs/AtomicStep\"\n",
      "            },\n",
      "            \"title\": \"Atomic Steps\",\n",
      "            \"type\": \"array\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"key\",\n",
      "          \"name\",\n",
      "          \"atomic_steps\"\n",
      "        ],\n",
      "        \"title\": \"FoundationObservation\",\n",
      "        \"type\": \"object\"\n",
      "      },\n",
      "      \"GuardRailEnum\": {\n",
      "        \"enum\": [\n",
      "          \"Creativity\",\n",
      "          \"Cultural Context\",\n",
      "          \"Budget\"\n",
      "        ],\n",
      "        \"title\": \"GuardRailEnum\",\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"ReasoningProcess\": {\n",
      "        \"properties\": {\n",
      "          \"foundation_observations\": {\n",
      "            \"description\": \"List of foundation observations that make up the reasoning process.\",\n",
      "            \"items\": {\n",
      "              \"$ref\": \"#/$defs/FoundationObservation\"\n",
      "            },\n",
      "            \"title\": \"Foundation Observations\",\n",
      "            \"type\": \"array\"\n",
      "          },\n",
      "          \"thoughts\": {\n",
      "            \"description\": \"List of thoughts that make up the reasoning process.\",\n",
      "            \"items\": {\n",
      "              \"$ref\": \"#/$defs/Thought\"\n",
      "            },\n",
      "            \"title\": \"Thoughts\",\n",
      "            \"type\": \"array\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"foundation_observations\",\n",
      "          \"thoughts\"\n",
      "        ],\n",
      "        \"title\": \"ReasoningProcess\",\n",
      "        \"type\": \"object\"\n",
      "      },\n",
      "      \"Thought\": {\n",
      "        \"properties\": {\n",
      "          \"key\": {\n",
      "            \"description\": \"Key of the thought. Must have format of TH_<number> (ex: TH_1, TH_2, etc.)\",\n",
      "            \"title\": \"Key\",\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"backtracked_from\": {\n",
      "            \"anyOf\": [\n",
      "              {\n",
      "                \"type\": \"string\"\n",
      "              },\n",
      "              {\n",
      "                \"const\": \"None\",\n",
      "                \"enum\": [\n",
      "                  \"None\"\n",
      "                ],\n",
      "                \"type\": \"string\"\n",
      "              }\n",
      "            ],\n",
      "            \"description\": \"If the thought is a backtrack, the key of the thought it was backtracked from (ex: TH_1, TH_2, etc.). If not, must be the literal string 'None'.\",\n",
      "            \"title\": \"Backtracked From\"\n",
      "          },\n",
      "          \"parent_thought\": {\n",
      "            \"anyOf\": [\n",
      "              {\n",
      "                \"type\": \"string\"\n",
      "              },\n",
      "              {\n",
      "                \"const\": \"None\",\n",
      "                \"enum\": [\n",
      "                  \"None\"\n",
      "                ],\n",
      "                \"type\": \"string\"\n",
      "              }\n",
      "            ],\n",
      "            \"description\": \"If the thought is a child thought of a previous thought, the key of the thought this thought was born from (ex: TH_1, TH_2, etc.). If not, must be the literal string 'None'.\",\n",
      "            \"title\": \"Parent Thought\"\n",
      "          },\n",
      "          \"associated_foundation_observations\": {\n",
      "            \"description\": \"List of keys of the foundation observations that this thought is associated with (ex: FO_1, FO_2, etc.).\",\n",
      "            \"items\": {\n",
      "              \"type\": \"string\"\n",
      "            },\n",
      "            \"title\": \"Associated Foundation Observations\",\n",
      "            \"type\": \"array\"\n",
      "          },\n",
      "          \"name\": {\n",
      "            \"description\": \"Use short, simple sentences that mirror natural thought patterns\",\n",
      "            \"title\": \"Name\",\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"guard_rails_to_consider\": {\n",
      "            \"description\": \"Guard rails to consider at this step.\",\n",
      "            \"items\": {\n",
      "              \"$ref\": \"#/$defs/GuardRailEnum\"\n",
      "            },\n",
      "            \"title\": \"Guard Rails To Consider\",\n",
      "            \"type\": \"array\"\n",
      "          },\n",
      "          \"thought_process\": {\n",
      "            \"description\": \"List of atomic steps that make up the thought.\",\n",
      "            \"items\": {\n",
      "              \"$ref\": \"#/$defs/AtomicStep\"\n",
      "            },\n",
      "            \"title\": \"Thought Process\",\n",
      "            \"type\": \"array\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"key\",\n",
      "          \"backtracked_from\",\n",
      "          \"parent_thought\",\n",
      "          \"associated_foundation_observations\",\n",
      "          \"name\",\n",
      "          \"guard_rails_to_consider\",\n",
      "          \"thought_process\"\n",
      "        ],\n",
      "        \"title\": \"Thought\",\n",
      "        \"type\": \"object\"\n",
      "      }\n",
      "    },\n",
      "    \"properties\": {\n",
      "      \"reasoning_process\": {\n",
      "        \"allOf\": [\n",
      "          {\n",
      "            \"$ref\": \"#/$defs/ReasoningProcess\"\n",
      "          }\n",
      "        ],\n",
      "        \"description\": \"The full, in-depth reasoning process used to arrive at this output.\"\n",
      "      },\n",
      "      \"findings_summary\": {\n",
      "        \"description\": \"An in depth summary of your findings.\",\n",
      "        \"title\": \"Findings Summary\",\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"remaining_questions\": {\n",
      "        \"description\": \"A list of remaining questions or areas for further investigation.\",\n",
      "        \"items\": {\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"title\": \"Remaining Questions\",\n",
      "        \"type\": \"array\"\n",
      "      },\n",
      "      \"is_conclusion_premature\": {\n",
      "        \"description\": \"Whether the conclusion is premature or not.\",\n",
      "        \"title\": \"Is Conclusion Premature\",\n",
      "        \"type\": \"boolean\"\n",
      "      },\n",
      "      \"reason_for_premature_conclusion\": {\n",
      "        \"anyOf\": [\n",
      "          {\n",
      "            \"const\": \"conclusion NOT premature\",\n",
      "            \"enum\": [\n",
      "              \"conclusion NOT premature\"\n",
      "            ],\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"string\"\n",
      "          }\n",
      "        ],\n",
      "        \"description\": \"If is_conclusion_premature is True, contains the reason why. If False, must be the literal string 'conclusion NOT premature'.\",\n",
      "        \"title\": \"Reason For Premature Conclusion\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"findings_summary\",\n",
      "      \"is_conclusion_premature\",\n",
      "      \"reason_for_premature_conclusion\",\n",
      "      \"reasoning_process\",\n",
      "      \"remaining_questions\"\n",
      "    ],\n",
      "    \"type\": \"object\"\n",
      "  }\n",
      "}\n",
      "</response model>\n",
      "\n",
      "</system prompt>\n",
      "\n",
      "\n",
      "<user prompt>\n",
      " Please provide a detailed step by step reasoning process for the following task:\n",
      "# Task: \n",
      "Create a new education system optimized for the age of artificial intelligence\n",
      "    \n",
      "# Guardrails:\n",
      "{\n",
      "  \"name\": \"Creativity\",\n",
      "  \"description\": \"Must preserve human creativity and critical thinking\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Cultural Context\",\n",
      "  \"description\": \"Should work across different cultural contexts\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Budget\",\n",
      "  \"description\": \"Cannot require more than current education budgets\"\n",
      "}\n",
      "</user prompt>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_prompt_for_gpt_prompt(TASK, GUARDRAILS, GuardRailEnum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flowchart TB\n",
      "\n",
      "subgraph Foundation Observations\n",
      "    subgraph FO_1[\"FO_1: Observing the current education landscape\"]\n",
      "    direction TB\n",
      "        FO_1_AS_1[\"AS_1: Education systems vary widely across the globe.\"]\n",
      "        FO_1_AS_2[\"AS_2: Many focus on standardized testing and rigid curricula.\"]\n",
      "        FO_1_AS_3[\"AS_3: Traditional models may not address emerging AI-driven job skills.\"]\n",
      "    end\n",
      "    subgraph FO_2[\"FO_2: Noting the impact of AI on job markets\"]\n",
      "    direction TB\n",
      "        FO_2_AS_4[\"AS_4: AI continues to automate routine tasks.\"]\n",
      "        FO_2_AS_5[\"AS_5: Human creativity and critical thinking become more essential.\"]\n",
      "        FO_2_AS_6[\"AS_6: Educational frameworks need to nurture innovative thinking.\"]\n",
      "    end\n",
      "    subgraph FO_3[\"FO_3: Constraints from cultural diversity and budgets\"]\n",
      "    direction TB\n",
      "        FO_3_AS_7[\"AS_7: Education systems must be flexible to different cultural values.\"]\n",
      "        FO_3_AS_8[\"AS_8: Any reform must stay within current budget limitations.\"]\n",
      "        FO_3_AS_9[\"AS_9: Leveraging existing resources could be critical.\"]\n",
      "    end\n",
      "    subgraph FO_4[\"FO_4: Further consideration: standardizing teacher training\"]\n",
      "    direction TB\n",
      "        FO_4_AS_20[\"AS_20: Teacher training must incorporate universal AI literacy principles.\"]\n",
      "        FO_4_AS_21[\"AS_21: Yet it needs to remain adaptable to local cultural contexts.\"]\n",
      "        FO_4_AS_22[\"AS_22: Centralized guidelines can help but should allow regional customization.\"]\n",
      "    end\n",
      "    subgraph FO_5[\"FO_5: Further consideration: measuring education success\"]\n",
      "    direction TB\n",
      "        FO_5_AS_23[\"AS_23: Traditional tests may not fully capture creative and critical skills.\"]\n",
      "        FO_5_AS_24[\"AS_24: Multi-faceted evaluations like portfolios, project work, and peer reviews could be used.\"]\n",
      "        FO_5_AS_25[\"AS_25: Practical, real-world tasks might better showcase readiness for an AI-driven environment.\"]\n",
      "    end\n",
      "    subgraph FO_6[\"FO_6: Further consideration: forging public-private partnerships\"]\n",
      "    direction TB\n",
      "        FO_6_AS_32[\"AS_32: Collaboration with tech companies could provide specialized AI resources.\"]\n",
      "        FO_6_AS_33[\"AS_33: Public sector oversight ensures equitable access and upholds cultural integrity.\"]\n",
      "        FO_6_AS_34[\"AS_34: Budget constraints could be eased through shared funding and in-kind tech support.\"]\n",
      "    end\n",
      "    subgraph FO_7[\"FO_7: Further consideration: governance and long-term updates\"]\n",
      "    direction TB\n",
      "        FO_7_AS_35[\"AS_35: AI and job markets evolve rapidly, requiring continuous curriculum updates.\"]\n",
      "        FO_7_AS_36[\"AS_36: A dedicated regulatory or advisory body might be necessary to guide ongoing reforms.\"]\n",
      "        FO_7_AS_37[\"AS_37: Such a body would need representation from educators, technologists, and cultural experts.\"]\n",
      "    end\n",
      "    subgraph FO_8[\"FO_8: Further consideration: mental and emotional well-being\"]\n",
      "    direction TB\n",
      "        FO_8_AS_44[\"AS_44: AI-driven workloads and new skill demands can lead to stress for students and teachers.\"]\n",
      "        FO_8_AS_45[\"AS_45: Social-emotional learning (SEL) should be integrated to build resilience.\"]\n",
      "        FO_8_AS_46[\"AS_46: Counseling services, digital or in-person, might be needed to sustain mental health.\"]\n",
      "    end\n",
      "    subgraph FO_9[\"FO_9: Further consideration: data privacy and security\"]\n",
      "    direction TB\n",
      "        FO_9_AS_47[\"AS_47: Digital platforms may collect large amounts of student data.\"]\n",
      "        FO_9_AS_48[\"AS_48: Data privacy regulations and secure infrastructure are essential.\"]\n",
      "        FO_9_AS_49[\"AS_49: Teachers, students, and parents need clarity on data usage and protection.\"]\n",
      "    end\n",
      "    subgraph FO_10[\"FO_10: Further consideration: supporting multi-lingual contexts\"]\n",
      "    direction TB\n",
      "        FO_10_AS_50[\"AS_50: AI can help create language learning tools and real-time translation aids.\"]\n",
      "        FO_10_AS_51[\"AS_51: Curricula should embrace local languages to ensure inclusivity and preserve cultural identity.\"]\n",
      "        FO_10_AS_52[\"AS_52: A multi-lingual approach can expand global collaboration but must remain feasible within budgets.\"]\n",
      "    end\n",
      "    subgraph FO_11[\"FO_11: Further consideration: advanced AI tools in the classroom\"]\n",
      "    direction TB\n",
      "        FO_11_AS_62[\"AS_62: Generative AI can personalize learning experiences and supplement teacher workloads.\"]\n",
      "        FO_11_AS_63[\"AS_63: Ethical considerations around student data and bias must be managed carefully.\"]\n",
      "        FO_11_AS_64[\"AS_64: Teachers need training on effectively blending advanced AI tools with traditional methods.\"]\n",
      "    end\n",
      "    subgraph FO_12[\"FO_12: Further consideration: lifelong learning and adult re-education\"]\n",
      "    direction TB\n",
      "        FO_12_AS_65[\"AS_65: Many adults face job displacement as AI automation grows.\"]\n",
      "        FO_12_AS_66[\"AS_66: Continuous upskilling programs can help them adapt to AI-driven industries.\"]\n",
      "        FO_12_AS_67[\"AS_67: Blended online/offline models could keep costs low and accommodate diverse schedules.\"]\n",
      "    end\n",
      "    subgraph FO_13[\"FO_13: Further consideration: bridging physical and digital infrastructure\"]\n",
      "    direction TB\n",
      "        FO_13_AS_74[\"AS_74: Some regions lack reliable internet or modern hardware resources.\"]\n",
      "        FO_13_AS_75[\"AS_75: Low-tech or offline-friendly AI teaching methods can help fill gaps.\"]\n",
      "        FO_13_AS_76[\"AS_76: Infrastructure partnerships might involve telecommunications, local governments, or NGOs.\"]\n",
      "    end\n",
      "    subgraph FO_14[\"FO_14: Further consideration: extracurriculars and AI literacy clubs\"]\n",
      "    direction TB\n",
      "        FO_14_AS_77[\"AS_77: Extracurricular clubs can foster applied AI projects in a more informal setting.\"]\n",
      "        FO_14_AS_78[\"AS_78: Community-driven or student-led clubs promote peer learning and enthusiasm.\"]\n",
      "        FO_14_AS_79[\"AS_79: Partnerships with local industries could sponsor equipment or mentorship for these clubs.\"]\n",
      "    end\n",
      "    subgraph FO_15[\"FO_15: Further consideration: incentivizing teacher retention\"]\n",
      "    direction TB\n",
      "        FO_15_AS_80[\"AS_80: Implementing AI-based curriculum can overwhelm teachers without proper support.\"]\n",
      "        FO_15_AS_81[\"AS_81: Professional growth opportunities, certifications, or stipends can incentivize teachers.\"]\n",
      "        FO_15_AS_82[\"AS_82: Encouraging teacher innovation and recognition helps maintain motivation and retention.\"]\n",
      "    end\n",
      "    subgraph FO_16[\"FO_16: Further consideration: bridging generational digital literacy for families\"]\n",
      "    direction TB\n",
      "        FO_16_AS_92[\"AS_92: Parents and guardians may lack familiarity with AI concepts being taught to students.\"]\n",
      "        FO_16_AS_93[\"AS_93: Workshops or community sessions can help families understand modern AI-driven curricula.\"]\n",
      "        FO_16_AS_94[\"AS_94: These efforts foster home support and alignment with school initiatives.\"]\n",
      "    end\n",
      "    subgraph FO_17[\"FO_17: Further consideration: interdisciplinary approaches across grade levels\"]\n",
      "    direction TB\n",
      "        FO_17_AS_95[\"AS_95: AI skills can benefit from integration into math, language, arts, and sciences alike.\"]\n",
      "        FO_17_AS_96[\"AS_96: Project-based learning can unify multiple subjects under AI-driven problem-solving.\"]\n",
      "        FO_17_AS_97[\"AS_97: Gradual scaling of complexity ensures consistency from early education to advanced levels.\"]\n",
      "    end\n",
      "    subgraph FO_18[\"FO_18: Further consideration: transition from secondary education to higher ed or workforce\"]\n",
      "    direction TB\n",
      "        FO_18_AS_98[\"AS_98: Students completing AI-centric secondary education need clear pathways to university and jobs.\"]\n",
      "        FO_18_AS_99[\"AS_99: Colleges may need to adapt entry requirements or offer bridging courses for advanced AI topics.\"]\n",
      "        FO_18_AS_100[\"AS_100: Apprenticeships and internships can support direct workforce entry in AI-related fields.\"]\n",
      "    end\n",
      "end\n",
      "\n",
      "subgraph Thoughts\n",
      "    subgraph TH_1[\"TH_1: Initial reflection on core needs\\n(backtracked_from: None)\\n(parent_thought: None)\\nAssociated FOs: [FO_1]\"]\n",
      "        subgraph GR_TH_1[\"Guard Rails\"]\n",
      "            GR_TH_1_1[\"Creativity\"]\n",
      "            GR_TH_1_2[\"Cultural Context\"]\n",
      "            GR_TH_1_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_1_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_1_AS_10[\"AS_10: We need a system that emphasizes innovation from early stages.\"]\n",
      "            TH_1_AS_11[\"AS_11: This must still accommodate varied cultural backgrounds.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_2[\"TH_2: Focus on AI’s role\\n(backtracked_from: None)\\n(parent_thought: TH_1)\\nAssociated FOs: [FO_2]\"]\n",
      "        subgraph GR_TH_2[\"Guard Rails\"]\n",
      "            GR_TH_2_1[\"Creativity\"]\n",
      "            GR_TH_2_2[\"Cultural Context\"]\n",
      "            GR_TH_2_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_2_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_2_AS_12[\"AS_12: AI demands skill in critical analysis and creative problem-solving.\"]\n",
      "            TH_2_AS_13[\"AS_13: The curriculum could include computational thinking and ethics.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_3[\"TH_3: Aligning with cultural and financial constraints\\n(backtracked_from: None)\\n(parent_thought: TH_2)\\nAssociated FOs: [FO_3]\"]\n",
      "        subgraph GR_TH_3[\"Guard Rails\"]\n",
      "            GR_TH_3_1[\"Creativity\"]\n",
      "            GR_TH_3_2[\"Cultural Context\"]\n",
      "            GR_TH_3_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_3_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_3_AS_14[\"AS_14: We can integrate local cultural examples to ensure relevance.\"]\n",
      "            TH_3_AS_15[\"AS_15: Reuse existing teacher training structures to manage cost.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_4[\"TH_4: Formulating the new AI-optimized education system\\n(backtracked_from: None)\\n(parent_thought: TH_3)\\nAssociated FOs: [FO_1, FO_2, FO_3]\"]\n",
      "        subgraph GR_TH_4[\"Guard Rails\"]\n",
      "            GR_TH_4_1[\"Creativity\"]\n",
      "            GR_TH_4_2[\"Cultural Context\"]\n",
      "            GR_TH_4_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_4_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_4_AS_16[\"AS_16: Propose a project-based curriculum emphasizing creativity and AI literacy.\"]\n",
      "            TH_4_AS_17[\"AS_17: Incorporate ethics, social context, and collaboration using cultural case studies.\"]\n",
      "            TH_4_AS_18[\"AS_18: Ensure teacher development is scaled within existing budget through blended learning.\"]\n",
      "            TH_4_AS_19[\"AS_19: This fosters critical thinking, adaptability, and cross-cultural understanding.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_5[\"TH_5: Deeper dive into standardizing teacher training\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_4]\"]\n",
      "        subgraph GR_TH_5[\"Guard Rails\"]\n",
      "            GR_TH_5_1[\"Creativity\"]\n",
      "            GR_TH_5_2[\"Cultural Context\"]\n",
      "            GR_TH_5_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_5_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_5_AS_26[\"AS_26: Create a universal AI-teaching framework with flexible cultural modules.\"]\n",
      "            TH_5_AS_27[\"AS_27: Encourage teacher exchanges and online communities to share best practices.\"]\n",
      "            TH_5_AS_28[\"AS_28: Incorporate ongoing professional development to keep up with AI advancements.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_6[\"TH_6: Exploring metrics for success in AI-era education\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_5]\"]\n",
      "        subgraph GR_TH_6[\"Guard Rails\"]\n",
      "            GR_TH_6_1[\"Creativity\"]\n",
      "            GR_TH_6_2[\"Cultural Context\"]\n",
      "            GR_TH_6_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_6_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_6_AS_29[\"AS_29: Adopt multi-dimensional evaluations including portfolios and collaborative projects.\"]\n",
      "            TH_6_AS_30[\"AS_30: Measure adaptability, creativity, and ethical decision-making as key outcomes.\"]\n",
      "            TH_6_AS_31[\"AS_31: Incentivize cross-disciplinary work to demonstrate real-world readiness.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_7[\"TH_7: Leveraging public-private collaborations\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_6]\"]\n",
      "        subgraph GR_TH_7[\"Guard Rails\"]\n",
      "            GR_TH_7_1[\"Creativity\"]\n",
      "            GR_TH_7_2[\"Cultural Context\"]\n",
      "            GR_TH_7_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_7_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_7_AS_38[\"AS_38: Establish partnerships with AI firms for resources and training materials.\"]\n",
      "            TH_7_AS_39[\"AS_39: Ensure public sector participation to safeguard equitable distribution of benefits.\"]\n",
      "            TH_7_AS_40[\"AS_40: Monitor and regulate budgets through shared responsibility and accountability frameworks.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_8[\"TH_8: Establishing governance for ongoing curriculum evolution\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_7]\"]\n",
      "        subgraph GR_TH_8[\"Guard Rails\"]\n",
      "            GR_TH_8_1[\"Creativity\"]\n",
      "            GR_TH_8_2[\"Cultural Context\"]\n",
      "            GR_TH_8_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_8_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_8_AS_41[\"AS_41: Form an interdisciplinary council to continually update AI-related coursework.\"]\n",
      "            TH_8_AS_42[\"AS_42: Include tech experts, educators, and cultural representatives for balanced guidance.\"]\n",
      "            TH_8_AS_43[\"AS_43: Require periodic reviews to ensure content remains culturally relevant and cost-feasible.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_9[\"TH_9: Addressing mental and emotional well-being\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_8]\"]\n",
      "        subgraph GR_TH_9[\"Guard Rails\"]\n",
      "            GR_TH_9_1[\"Creativity\"]\n",
      "            GR_TH_9_2[\"Cultural Context\"]\n",
      "            GR_TH_9_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_9_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_9_AS_53[\"AS_53: Incorporate social-emotional learning across subjects to reduce AI-related stress.\"]\n",
      "            TH_9_AS_54[\"AS_54: Train educators in recognizing burnout and emotional health challenges.\"]\n",
      "            TH_9_AS_55[\"AS_55: Allocate part of existing budgets for mental health support, possibly via digital counseling.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_10[\"TH_10: Ensuring robust data privacy and security\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_9]\"]\n",
      "        subgraph GR_TH_10[\"Guard Rails\"]\n",
      "            GR_TH_10_1[\"Creativity\"]\n",
      "            GR_TH_10_2[\"Cultural Context\"]\n",
      "            GR_TH_10_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_10_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_10_AS_56[\"AS_56: Establish clear data handling policies for any AI tools used in classrooms.\"]\n",
      "            TH_10_AS_57[\"AS_57: Enforce compliance with local and international privacy regulations.\"]\n",
      "            TH_10_AS_58[\"AS_58: Offer transparent guidelines for parents, teachers, and students on data usage.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_11[\"TH_11: Expanding multi-lingual and global collaboration\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_10]\"]\n",
      "        subgraph GR_TH_11[\"Guard Rails\"]\n",
      "            GR_TH_11_1[\"Creativity\"]\n",
      "            GR_TH_11_2[\"Cultural Context\"]\n",
      "            GR_TH_11_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_11_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_11_AS_59[\"AS_59: Implement AI translation tools to support diverse language learners.\"]\n",
      "            TH_11_AS_60[\"AS_60: Develop bilingual or multi-lingual curricula to preserve cultural identity.\"]\n",
      "            TH_11_AS_61[\"AS_61: Balance costs by leveraging open-source AI language platforms where feasible.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_12[\"TH_12: Incorporating advanced AI tools in classrooms\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_11]\"]\n",
      "        subgraph GR_TH_12[\"Guard Rails\"]\n",
      "            GR_TH_12_1[\"Creativity\"]\n",
      "            GR_TH_12_2[\"Cultural Context\"]\n",
      "            GR_TH_12_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_12_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_12_AS_68[\"AS_68: Explore generative AI for personalized learning content and real-time feedback loops.\"]\n",
      "            TH_12_AS_69[\"AS_69: Set ethical guidelines around AI usage and ensure teacher moderation.\"]\n",
      "            TH_12_AS_70[\"AS_70: Budget for necessary hardware or software, exploring open-source solutions to reduce cost.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_13[\"TH_13: Building lifelong learning and re-education pathways\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_12]\"]\n",
      "        subgraph GR_TH_13[\"Guard Rails\"]\n",
      "            GR_TH_13_1[\"Creativity\"]\n",
      "            GR_TH_13_2[\"Cultural Context\"]\n",
      "            GR_TH_13_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_13_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_13_AS_71[\"AS_71: Develop modular courses for adults facing AI-related job shifts.\"]\n",
      "            TH_13_AS_72[\"AS_72: Partner with community colleges, online platforms, and local businesses for real-world skill alignment.\"]\n",
      "            TH_13_AS_73[\"AS_73: Offer flexible scheduling and scholarship options to ensure accessibility and equity.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_14[\"TH_14: Bridging physical and digital infrastructure gaps\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_13]\"]\n",
      "        subgraph GR_TH_14[\"Guard Rails\"]\n",
      "            GR_TH_14_1[\"Creativity\"]\n",
      "            GR_TH_14_2[\"Cultural Context\"]\n",
      "            GR_TH_14_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_14_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_14_AS_83[\"AS_83: Collaborate with telecom providers and local governments to expand internet access.\"]\n",
      "            TH_14_AS_84[\"AS_84: Develop offline or low-tech AI learning resources for underserved areas.\"]\n",
      "            TH_14_AS_85[\"AS_85: Use NGO partnerships to distribute hardware or set up community tech centers.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_15[\"TH_15: Promoting extracurricular AI clubs for deeper engagement\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_14]\"]\n",
      "        subgraph GR_TH_15[\"Guard Rails\"]\n",
      "            GR_TH_15_1[\"Creativity\"]\n",
      "            GR_TH_15_2[\"Cultural Context\"]\n",
      "            GR_TH_15_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_15_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_15_AS_86[\"AS_86: Encourage student-led AI clubs to foster hands-on experimentation.\"]\n",
      "            TH_15_AS_87[\"AS_87: Offer mentorship from local tech experts or university faculty where possible.\"]\n",
      "            TH_15_AS_88[\"AS_88: Organize competitions and showcases to spur innovation and share learnings.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_16[\"TH_16: Strengthening teacher retention and motivation\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_15]\"]\n",
      "        subgraph GR_TH_16[\"Guard Rails\"]\n",
      "            GR_TH_16_1[\"Creativity\"]\n",
      "            GR_TH_16_2[\"Cultural Context\"]\n",
      "            GR_TH_16_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_16_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_16_AS_89[\"AS_89: Provide recognition and tangible rewards for teachers who excel at AI-oriented instruction.\"]\n",
      "            TH_16_AS_90[\"AS_90: Offer advanced training certifications and career advancement pathways.\"]\n",
      "            TH_16_AS_91[\"AS_91: Incentivize teachers to pilot new methods and share results within professional networks.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_17[\"TH_17: Improving generational digital literacy\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_16]\"]\n",
      "        subgraph GR_TH_17[\"Guard Rails\"]\n",
      "            GR_TH_17_1[\"Creativity\"]\n",
      "            GR_TH_17_2[\"Cultural Context\"]\n",
      "            GR_TH_17_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_17_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_17_AS_92[\"AS_92: Host parent/guardian AI literacy sessions to align home support with school lessons.\"]\n",
      "            TH_17_AS_93[\"AS_93: Provide simple resources or tutorials, possibly in multiple languages.\"]\n",
      "            TH_17_AS_94[\"AS_94: Encourage family engagement nights where students showcase AI projects to relatives.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_18[\"TH_18: Advancing interdisciplinary methods\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_17]\"]\n",
      "        subgraph GR_TH_18[\"Guard Rails\"]\n",
      "            GR_TH_18_1[\"Creativity\"]\n",
      "            GR_TH_18_2[\"Cultural Context\"]\n",
      "            GR_TH_18_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_18_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_18_AS_95[\"AS_95: Blend math, language, and arts with AI topics for cross-subject synergy.\"]\n",
      "            TH_18_AS_96[\"AS_96: Design thematic units where students apply AI in real-world problems spanning multiple disciplines.\"]\n",
      "            TH_18_AS_97[\"AS_97: Scale difficulty from elementary to secondary levels, ensuring a cohesive learning progression.\"]\n",
      "        end\n",
      "    end\n",
      "    subgraph TH_19[\"TH_19: Navigating transitions to higher education or workforce\\n(backtracked_from: None)\\n(parent_thought: TH_4)\\nAssociated FOs: [FO_18]\"]\n",
      "        subgraph GR_TH_19[\"Guard Rails\"]\n",
      "            GR_TH_19_1[\"Creativity\"]\n",
      "            GR_TH_19_2[\"Cultural Context\"]\n",
      "            GR_TH_19_3[\"Budget\"]\n",
      "        end\n",
      "        subgraph TH_19_AtomicSteps[\"Thought Process\"]\n",
      "    direction TB\n",
      "            TH_19_AS_98[\"AS_98: Coordinate with universities to recognize AI-focused high school curricula for admissions.\"]\n",
      "            TH_19_AS_99[\"AS_99: Offer bridging courses or summer programs for advanced AI or specialized technical skills.\"]\n",
      "            TH_19_AS_100[\"AS_100: Develop internship pipelines with local industries for graduates entering the workforce.\"]\n",
      "        end\n",
      "    end\n",
      "end\n",
      "\n",
      "FO_1 --> TH_1\n",
      "FO_2 --> TH_2\n",
      "FO_3 --> TH_3\n",
      "FO_1 --> TH_4\n",
      "FO_2 --> TH_4\n",
      "FO_3 --> TH_4\n",
      "FO_4 --> TH_5\n",
      "FO_5 --> TH_6\n",
      "FO_6 --> TH_7\n",
      "FO_7 --> TH_8\n",
      "FO_8 --> TH_9\n",
      "FO_9 --> TH_10\n",
      "FO_10 --> TH_11\n",
      "FO_11 --> TH_12\n",
      "FO_12 --> TH_13\n",
      "FO_13 --> TH_14\n",
      "FO_14 --> TH_15\n",
      "FO_15 --> TH_16\n",
      "FO_16 --> TH_17\n",
      "FO_17 --> TH_18\n",
      "FO_18 --> TH_19\n",
      "TH_1 --> TH_2\n",
      "TH_2 --> TH_3\n",
      "TH_3 --> TH_4\n",
      "TH_4 --> TH_5\n",
      "TH_4 --> TH_6\n",
      "TH_4 --> TH_7\n",
      "TH_4 --> TH_8\n",
      "TH_4 --> TH_9\n",
      "TH_4 --> TH_10\n",
      "TH_4 --> TH_11\n",
      "TH_4 --> TH_12\n",
      "TH_4 --> TH_13\n",
      "TH_4 --> TH_14\n",
      "TH_4 --> TH_15\n",
      "TH_4 --> TH_16\n",
      "TH_4 --> TH_17\n",
      "TH_4 --> TH_18\n",
      "TH_4 --> TH_19\n",
      "FO_1_AS_1 --> FO_1_AS_2\n",
      "FO_1_AS_2 --> FO_1_AS_3\n",
      "FO_2_AS_4 --> FO_2_AS_5\n",
      "FO_2_AS_5 --> FO_2_AS_6\n",
      "FO_3_AS_7 --> FO_3_AS_8\n",
      "FO_3_AS_8 --> FO_3_AS_9\n",
      "FO_4_AS_20 --> FO_4_AS_21\n",
      "FO_4_AS_21 --> FO_4_AS_22\n",
      "FO_5_AS_23 --> FO_5_AS_24\n",
      "FO_5_AS_24 --> FO_5_AS_25\n",
      "FO_6_AS_32 --> FO_6_AS_33\n",
      "FO_6_AS_33 --> FO_6_AS_34\n",
      "FO_7_AS_35 --> FO_7_AS_36\n",
      "FO_7_AS_36 --> FO_7_AS_37\n",
      "FO_8_AS_44 --> FO_8_AS_45\n",
      "FO_8_AS_45 --> FO_8_AS_46\n",
      "FO_9_AS_47 --> FO_9_AS_48\n",
      "FO_9_AS_48 --> FO_9_AS_49\n",
      "FO_10_AS_50 --> FO_10_AS_51\n",
      "FO_10_AS_51 --> FO_10_AS_52\n",
      "FO_11_AS_62 --> FO_11_AS_63\n",
      "FO_11_AS_63 --> FO_11_AS_64\n",
      "FO_12_AS_65 --> FO_12_AS_66\n",
      "FO_12_AS_66 --> FO_12_AS_67\n",
      "FO_13_AS_74 --> FO_13_AS_75\n",
      "FO_13_AS_75 --> FO_13_AS_76\n",
      "FO_14_AS_77 --> FO_14_AS_78\n",
      "FO_14_AS_78 --> FO_14_AS_79\n",
      "FO_15_AS_80 --> FO_15_AS_81\n",
      "FO_15_AS_81 --> FO_15_AS_82\n",
      "FO_16_AS_92 --> FO_16_AS_93\n",
      "FO_16_AS_93 --> FO_16_AS_94\n",
      "FO_17_AS_95 --> FO_17_AS_96\n",
      "FO_17_AS_96 --> FO_17_AS_97\n",
      "FO_18_AS_98 --> FO_18_AS_99\n",
      "FO_18_AS_99 --> FO_18_AS_100\n",
      "TH_1_AS_10 --> TH_1_AS_11\n",
      "TH_2_AS_12 --> TH_2_AS_13\n",
      "TH_3_AS_14 --> TH_3_AS_15\n",
      "TH_4_AS_16 --> TH_4_AS_17\n",
      "TH_4_AS_17 --> TH_4_AS_18\n",
      "TH_4_AS_18 --> TH_4_AS_19\n",
      "TH_5_AS_26 --> TH_5_AS_27\n",
      "TH_5_AS_27 --> TH_5_AS_28\n",
      "TH_6_AS_29 --> TH_6_AS_30\n",
      "TH_6_AS_30 --> TH_6_AS_31\n",
      "TH_7_AS_38 --> TH_7_AS_39\n",
      "TH_7_AS_39 --> TH_7_AS_40\n",
      "TH_8_AS_41 --> TH_8_AS_42\n",
      "TH_8_AS_42 --> TH_8_AS_43\n",
      "TH_9_AS_53 --> TH_9_AS_54\n",
      "TH_9_AS_54 --> TH_9_AS_55\n",
      "TH_10_AS_56 --> TH_10_AS_57\n",
      "TH_10_AS_57 --> TH_10_AS_58\n",
      "TH_11_AS_59 --> TH_11_AS_60\n",
      "TH_11_AS_60 --> TH_11_AS_61\n",
      "TH_12_AS_68 --> TH_12_AS_69\n",
      "TH_12_AS_69 --> TH_12_AS_70\n",
      "TH_13_AS_71 --> TH_13_AS_72\n",
      "TH_13_AS_72 --> TH_13_AS_73\n",
      "TH_14_AS_83 --> TH_14_AS_84\n",
      "TH_14_AS_84 --> TH_14_AS_85\n",
      "TH_15_AS_86 --> TH_15_AS_87\n",
      "TH_15_AS_87 --> TH_15_AS_88\n",
      "TH_16_AS_89 --> TH_16_AS_90\n",
      "TH_16_AS_90 --> TH_16_AS_91\n",
      "TH_17_AS_92 --> TH_17_AS_93\n",
      "TH_17_AS_93 --> TH_17_AS_94\n",
      "TH_18_AS_95 --> TH_18_AS_96\n",
      "TH_18_AS_96 --> TH_18_AS_97\n",
      "TH_19_AS_98 --> TH_19_AS_99\n",
      "TH_19_AS_99 --> TH_19_AS_100\n"
     ]
    }
   ],
   "source": [
    "with open('../data/education_system/response_7.json', 'r') as f:\n",
    "    gpt_pro_response = json.load(f)\n",
    "    \n",
    "diagram_text = build_mermaid_diagram(gpt_pro_response['parameters'], is_gpt_prompt=True)\n",
    "print(diagram_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
